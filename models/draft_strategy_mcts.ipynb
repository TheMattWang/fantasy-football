{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i9qEbXb3Vbi"
      },
      "source": [
        "# Fantasy Football Draft Strategy with MCTS\n",
        "\n",
        "This notebook implements a Monte Carlo Tree Search (MCTS) based draft strategy that uses:\n",
        "- **VORP-based player valuations** from your draft board\n",
        "- **Rookie uncertainty modeling** from your ML pipeline\n",
        "- **Opponent modeling** using ADP with stochastic sampling\n",
        "- **Long-horizon planning** via MCTS with value function approximation\n",
        "\n",
        "## Key Components:\n",
        "1. **State Representation**: Round, roster composition, available players, picks until next turn\n",
        "2. **Action Space**: Available players (with masking for roster constraints)\n",
        "3. **Opponent Model**: Plackett-Luce sampling from ADP with position runs\n",
        "4. **Reward Function**: Roster-aware VORP with risk penalties and positional scarcity\n",
        "5. **MCTS Planning**: 400-800 simulations per decision with heuristic value function\n",
        "\n",
        "## Implementation Strategy:\n",
        "- Start with MCTS + heuristic value (Option C from the plan)\n",
        "- Use existing VORP data and rookie uncertainty\n",
        "- Minimal hyperparameter tuning (focus on Œª risk penalty and MCTS simulation count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIp1vQpn3Vbj"
      },
      "source": [
        "## 1. Setup and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_vtLZ6B3Vbj",
        "outputId": "3531b052-8f2f-4a0e-efbb-1ce45ac0c6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ CUDA Available: True\n",
            "üéØ GPU Device: Tesla T4\n",
            "üíæ GPU Memory: 15.8 GB\n",
            "üî• CUDA Cores: 40\n",
            "‚ö° T4 GPU detected - applying optimizations\n",
            "‚úÖ Setup complete!\n",
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages for Colab with GPU acceleration\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
        "%pip install pandas numpy matplotlib seaborn scipy numba cupy-cuda11x --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "# GPU acceleration imports\n",
        "try:\n",
        "    import torch\n",
        "    import cupy as cp\n",
        "    from numba import cuda, jit\n",
        "\n",
        "    GPU_AVAILABLE = torch.cuda.is_available()\n",
        "    print(f\"üöÄ CUDA Available: {GPU_AVAILABLE}\")\n",
        "\n",
        "    if GPU_AVAILABLE:\n",
        "        device = torch.cuda.current_device()\n",
        "        gpu_name = torch.cuda.get_device_name(device)\n",
        "        gpu_memory = torch.cuda.get_device_properties(device).total_memory / 1e9\n",
        "\n",
        "        print(f\"üéØ GPU Device: {gpu_name}\")\n",
        "        print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
        "        print(f\"üî• CUDA Cores: {torch.cuda.get_device_properties(device).multi_processor_count}\")\n",
        "\n",
        "        # Optimize for T4 GPU\n",
        "        if \"T4\" in gpu_name:\n",
        "            print(\"‚ö° T4 GPU detected - applying optimizations\")\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # Set memory growth to avoid OOM\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"üìä No GPU detected - using CPU (will be slower)\")\n",
        "\n",
        "except ImportError:\n",
        "    GPU_AVAILABLE = False\n",
        "    print(\"üìä GPU libraries not available - installing CPU-only versions\")\n",
        "    print(\"üí° For GPU acceleration, ensure you're using a GPU runtime\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "if 'torch' in globals():\n",
        "    torch.manual_seed(42)\n",
        "    if GPU_AVAILABLE:\n",
        "        torch.cuda.manual_seed(42)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "import seaborn as sns\n",
        "from scipy.stats import rankdata\n",
        "from typing import Dict, List, Tuple, Optional, Set\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "import math\n",
        "import pickle\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_uzr_cH3Vbj"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2sZNHZk3Vbk",
        "outputId": "7714b5be-4636-4539-9798-264fbde6972a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Starting data loading process...\n",
            "üì¶ Found colab_data.zip - extracting...\n",
            "‚úÖ ZIP file extracted successfully\n",
            "üîÑ Running colab_loader.py...\n",
            "üîÑ Loading data files...\n",
            "‚úÖ Data files detected!\n",
            "üìã Loaded metadata\n",
            "üìä Loaded draft_board.csv: 594 players\n",
            "üìà Loaded ADP data: 378 players\n",
            "üèà Loaded rookie data: 501 players\n",
            "ü§ñ Found rookie prediction model: rookie_regressor.pkl\n",
            "üéØ All critical data loaded successfully!\n",
            "\n",
            "üéØ Data loading complete!\n",
            "   üìä Draft board: 594 players\n",
            "   üìà ADP data: 378 players\n",
            "\n",
            "üìã Draft Board Preview:\n",
            "      player_name position  proj_ppg_2025       VORP  adp_rank\n",
            "0  Saquon Barkley       RB      21.435000  10.676176       3.0\n",
            "1    Jahmyr Gibbs       RB      20.188889   9.430065       4.0\n",
            "2   Derrick Henry       RB      19.678947   8.920124       7.0\n",
            "\n",
            "üìà ADP Data Preview:\n",
            "   Rank          Player Team   Bye  POS  Yahoo  Sleeper  RTSports  AVG Real-Time (?)\n",
            "0   1.0   Ja'Marr Chase  CIN  10.0  WR1    1.0      1.0       1.0  1.0             1\n",
            "1   2.0  Bijan Robinson  ATL   5.0  RB1    2.0      3.0       2.0  2.3             2\n",
            "2   3.0  Saquon Barkley  PHI   9.0  RB2    3.0      2.0       4.0  3.0             3\n",
            "\n",
            "‚úÖ Data loading section complete!\n"
          ]
        }
      ],
      "source": [
        "# Robust data loading with multiple fallback methods\n",
        "# =============================================================================\n",
        "\n",
        "# Initialize global variables\n",
        "draft_board = None\n",
        "adp_data = None\n",
        "metadata = None\n",
        "rookie_data = None\n",
        "\n",
        "def load_data_sources():\n",
        "    \"\"\"Load data from multiple sources with proper error handling\"\"\"\n",
        "\n",
        "    global draft_board, adp_data, metadata, rookie_data\n",
        "\n",
        "    # Try Method 1: Pre-packaged ZIP file (recommended)\n",
        "    if os.path.exists('colab_data.zip'):\n",
        "        print(\"üì¶ Found colab_data.zip - extracting...\")\n",
        "        try:\n",
        "            import zipfile\n",
        "            with zipfile.ZipFile('colab_data.zip', 'r') as zip_ref:\n",
        "                zip_ref.extractall('.')\n",
        "            print(\"‚úÖ ZIP file extracted successfully\")\n",
        "\n",
        "            # Load the data using the colab_loader if it exists\n",
        "            if os.path.exists('colab_loader.py'):\n",
        "                print(\"üîÑ Running colab_loader.py...\")\n",
        "                exec(open('colab_loader.py').read())\n",
        "                return True\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  colab_loader.py not found in ZIP, loading files directly...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ZIP extraction failed: {e}\")\n",
        "\n",
        "    # Try Method 2: Direct file loading (files already present)\n",
        "    if os.path.exists('draft_board.csv') and os.path.exists('FantasyPros_2025_Overall_ADP_Rankings.csv'):\n",
        "        print(\"üìä Loading data files directly...\")\n",
        "        try:\n",
        "            draft_board = pd.read_csv('draft_board.csv')\n",
        "            adp_data = pd.read_csv('FantasyPros_2025_Overall_ADP_Rankings.csv')\n",
        "\n",
        "            # Load metadata if available\n",
        "            if os.path.exists('metadata.json'):\n",
        "                import json\n",
        "                with open('metadata.json', 'r') as f:\n",
        "                    metadata = json.load(f)\n",
        "                print(\"üìã Loaded configuration metadata\")\n",
        "            else:\n",
        "                metadata = {'league_settings': {'teams': 12}, 'model_parameters': {}}\n",
        "\n",
        "            # Load rookie data if available\n",
        "            if os.path.exists('rookie_data_clean.csv'):\n",
        "                rookie_data = pd.read_csv('rookie_data_clean.csv')\n",
        "                print(f\"üèà Loaded rookie data: {len(rookie_data)} players\")\n",
        "\n",
        "            print(f\"‚úÖ Loaded {len(draft_board)} players from draft board\")\n",
        "            print(f\"‚úÖ Loaded {len(adp_data)} players from ADP rankings\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Direct file loading failed: {e}\")\n",
        "\n",
        "    # Try Method 3: Manual upload\n",
        "    try:\n",
        "        print(\"\\nüì§ Method 3: Manual File Upload\")\n",
        "        print(\"Please upload your CSV files:\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        # Check what was uploaded\n",
        "        if 'draft_board.csv' in uploaded and 'FantasyPros_2025_Overall_ADP_Rankings.csv' in uploaded:\n",
        "            draft_board = pd.read_csv('draft_board.csv')\n",
        "            adp_data = pd.read_csv('FantasyPros_2025_Overall_ADP_Rankings.csv')\n",
        "            metadata = {'league_settings': {'teams': 12}, 'model_parameters': {}}\n",
        "\n",
        "            print(f\"‚úÖ Uploaded and loaded {len(draft_board)} players from draft board\")\n",
        "            print(f\"‚úÖ Uploaded and loaded {len(adp_data)} players from ADP rankings\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Required CSV files not uploaded\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Manual upload failed: {e}\")\n",
        "\n",
        "    # Try Method 4: Google Drive mount\n",
        "    try:\n",
        "        print(\"\\nüíæ Method 4: Google Drive Mount\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        # Common Google Drive paths\n",
        "        drive_paths = [\n",
        "            '/content/drive/MyDrive/fantasy-football/',\n",
        "            '/content/drive/MyDrive/colab-data/',\n",
        "            '/content/drive/MyDrive/'\n",
        "        ]\n",
        "\n",
        "        for drive_path in drive_paths:\n",
        "            draft_path = os.path.join(drive_path, 'draft_board.csv')\n",
        "            adp_path = os.path.join(drive_path, 'FantasyPros_2025_Overall_ADP_Rankings.csv')\n",
        "\n",
        "            if os.path.exists(draft_path) and os.path.exists(adp_path):\n",
        "                draft_board = pd.read_csv(draft_path)\n",
        "                adp_data = pd.read_csv(adp_path)\n",
        "                metadata = {'league_settings': {'teams': 12}, 'model_parameters': {}}\n",
        "\n",
        "                print(f\"‚úÖ Loaded from Drive: {len(draft_board)} players from draft board\")\n",
        "                print(f\"‚úÖ Loaded from Drive: {len(adp_data)} players from ADP rankings\")\n",
        "                return True\n",
        "\n",
        "        print(\"‚ö†Ô∏è  CSV files not found in common Drive locations\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Google Drive mount failed: {e}\")\n",
        "\n",
        "    # Method 5: Generate sample data\n",
        "    print(\"\\nüé≤ Method 5: Using Sample Data\")\n",
        "    print(\"Creating sample data for demonstration...\")\n",
        "\n",
        "    # Generate realistic sample data\n",
        "    sample_draft_data = []\n",
        "    sample_adp_data = []\n",
        "\n",
        "    # Sample top players with realistic stats\n",
        "    top_players = [\n",
        "        ('Christian McCaffrey', 'RB', 10.5, 21.3, 1),\n",
        "        ('Tyreek Hill', 'WR', 9.8, 19.7, 2),\n",
        "        ('Travis Kelce', 'TE', 8.9, 17.2, 3),\n",
        "        ('Josh Allen', 'QB', 8.2, 22.1, 4),\n",
        "        ('Austin Ekeler', 'RB', 7.8, 18.5, 5),\n",
        "        ('Stefon Diggs', 'WR', 7.5, 17.8, 6),\n",
        "        ('Davante Adams', 'WR', 7.2, 17.1, 7),\n",
        "        ('Jonathan Taylor', 'RB', 6.9, 16.8, 8),\n",
        "        ('Cooper Kupp', 'WR', 6.6, 16.3, 9),\n",
        "        ('Derrick Henry', 'RB', 6.3, 15.9, 10)\n",
        "    ]\n",
        "\n",
        "    for i, (name, pos, vorp, ppg, adp) in enumerate(top_players):\n",
        "        sample_draft_data.append({\n",
        "            'player_name': name, 'position': pos, 'VORP': vorp,\n",
        "            'proj_ppg_2025': ppg, 'adp_rank': adp\n",
        "        })\n",
        "        sample_adp_data.append({\n",
        "            'player_name': name, 'position': pos, 'adp_rank': adp\n",
        "        })\n",
        "\n",
        "    # Add more players for realistic dataset\n",
        "    for i in range(11, 200):\n",
        "        pos = ['QB', 'RB', 'WR', 'TE', 'DEF', 'K'][i % 6]\n",
        "        sample_draft_data.append({\n",
        "            'player_name': f'Player_{i}', 'position': pos,\n",
        "            'VORP': max(0, 8 - i*0.05), 'proj_ppg_2025': max(5, 20 - i*0.08),\n",
        "            'adp_rank': i\n",
        "        })\n",
        "        sample_adp_data.append({\n",
        "            'player_name': f'Player_{i}', 'position': pos, 'adp_rank': i\n",
        "        })\n",
        "\n",
        "    draft_board = pd.DataFrame(sample_draft_data)\n",
        "    adp_data = pd.DataFrame(sample_adp_data)\n",
        "    metadata = {'league_settings': {'teams': 12}, 'model_parameters': {}}\n",
        "\n",
        "    print(f\"‚úÖ Generated sample data: {len(draft_board)} players\")\n",
        "    return True\n",
        "\n",
        "# Execute the data loading\n",
        "print(\"üîÑ Starting data loading process...\")\n",
        "try:\n",
        "    success = load_data_sources()\n",
        "    if success and draft_board is not None and adp_data is not None:\n",
        "        print(f\"\\nüéØ Data loading complete!\")\n",
        "        print(f\"   üìä Draft board: {len(draft_board)} players\")\n",
        "        print(f\"   üìà ADP data: {len(adp_data)} players\")\n",
        "\n",
        "        # Show data preview\n",
        "        print(f\"\\nüìã Draft Board Preview:\")\n",
        "        print(draft_board.head(3).to_string())\n",
        "        print(f\"\\nüìà ADP Data Preview:\")\n",
        "        print(adp_data.head(3).to_string())\n",
        "    else:\n",
        "        print(\"‚ùå Data loading failed!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Critical error in data loading: {e}\")\n",
        "    print(\"üìù Please check your files and try again\")\n",
        "\n",
        "print(\"\\n‚úÖ Data loading section complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qax0PLOw3Vbl"
      },
      "source": [
        "## 2. Data Structures and Game State\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR-Bgqpk3Vbl",
        "outputId": "b8f1ae29-167b-4196-b7b9-37acb31f1799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data structures defined!\n",
            "üèà League: 12 teams, 15 rounds\n",
            "üìã Roster: {'QB': 1, 'RB': 2, 'WR': 2, 'TE': 1, 'FLEX': 1, 'DEF': 1, 'K': 1, 'BENCH': 6}\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Player:\n",
        "    \"\"\"Represents a fantasy football player\"\"\"\n",
        "    name: str\n",
        "    position: str\n",
        "    team: str = \"\"\n",
        "    vorp: float = 0.0\n",
        "    proj_ppg: float = 0.0\n",
        "    adp_rank: float = 999.0\n",
        "    bye_week: int = 0\n",
        "    risk_sigma: float = 0.0  # Uncertainty/variance for rookies\n",
        "    is_rookie: bool = False\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.name)\n",
        "\n",
        "@dataclass\n",
        "class LeagueSettings:\n",
        "    \"\"\"League configuration\"\"\"\n",
        "    teams: int = 12\n",
        "    roster_spots: Dict[str, int] = field(default_factory=lambda: {\n",
        "        'QB': 1, 'RB': 2, 'WR': 2, 'TE': 1, 'FLEX': 1, 'DEF': 1, 'K': 1, 'BENCH': 6\n",
        "    })\n",
        "    flex_positions: Set[str] = field(default_factory=lambda: {'RB', 'WR', 'TE'})\n",
        "    total_rounds: int = 15\n",
        "\n",
        "    @property\n",
        "    def total_roster_size(self):\n",
        "        return sum(self.roster_spots.values())\n",
        "\n",
        "@dataclass\n",
        "class DraftState:\n",
        "    \"\"\"Current state of the draft\"\"\"\n",
        "    league: LeagueSettings\n",
        "    current_round: int = 1\n",
        "    current_pick_in_round: int = 1\n",
        "    available_players: Set[Player] = field(default_factory=set)\n",
        "    team_rosters: Dict[int, List[Player]] = field(default_factory=lambda: defaultdict(list))\n",
        "    our_team_id: int = 1\n",
        "\n",
        "    @property\n",
        "    def current_overall_pick(self):\n",
        "        return (self.current_round - 1) * self.league.teams + self.current_pick_in_round\n",
        "\n",
        "    @property\n",
        "    def is_snake_draft(self):\n",
        "        return True  # Assuming snake draft\n",
        "\n",
        "    @property\n",
        "    def current_team_picking(self):\n",
        "        if self.current_round % 2 == 1:  # Odd rounds\n",
        "            return self.current_pick_in_round\n",
        "        else:  # Even rounds (snake)\n",
        "            return self.league.teams - self.current_pick_in_round + 1\n",
        "\n",
        "    @property\n",
        "    def picks_until_our_turn(self):\n",
        "        current_team = self.current_team_picking\n",
        "        if current_team == self.our_team_id:\n",
        "            return 0\n",
        "\n",
        "        # Calculate picks until our next turn in snake draft\n",
        "        if self.current_round % 2 == 1:  # Odd round\n",
        "            if self.our_team_id > current_team:\n",
        "                return self.our_team_id - current_team\n",
        "            else:\n",
        "                # Need to go through end of round and back\n",
        "                picks_to_end = self.league.teams - current_team + 1\n",
        "                picks_back = self.league.teams - self.our_team_id + 1\n",
        "                return picks_to_end + picks_back\n",
        "        else:  # Even round\n",
        "            reverse_team = self.league.teams - current_team + 1\n",
        "            reverse_our_team = self.league.teams - self.our_team_id + 1\n",
        "            if reverse_our_team > reverse_team:\n",
        "                return reverse_our_team - reverse_team\n",
        "            else:\n",
        "                # Need to go to next round\n",
        "                picks_to_end = reverse_team\n",
        "                return picks_to_end + self.our_team_id\n",
        "\n",
        "    def get_roster_needs(self, team_id: int) -> Dict[str, int]:\n",
        "        \"\"\"Calculate remaining needs for a team\"\"\"\n",
        "        roster = self.team_rosters[team_id]\n",
        "        position_counts = Counter(p.position for p in roster)\n",
        "\n",
        "        needs = {}\n",
        "        for pos, required in self.league.roster_spots.items():\n",
        "            if pos == 'FLEX':\n",
        "                # FLEX can be filled by RB/WR/TE\n",
        "                flex_filled = sum(max(0, position_counts.get(fp, 0) - self.league.roster_spots.get(fp, 0))\n",
        "                                for fp in self.league.flex_positions)\n",
        "                needs[pos] = max(0, required - flex_filled)\n",
        "            elif pos == 'BENCH':\n",
        "                total_players = len(roster)\n",
        "                starting_spots = sum(v for k, v in self.league.roster_spots.items() if k != 'BENCH')\n",
        "                needs[pos] = max(0, required - (total_players - starting_spots))\n",
        "            else:\n",
        "                needs[pos] = max(0, required - position_counts.get(pos, 0))\n",
        "\n",
        "        return needs\n",
        "\n",
        "    def is_draft_complete(self) -> bool:\n",
        "        return self.current_round > self.league.total_rounds\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"Create a deep copy of the state\"\"\"\n",
        "        return deepcopy(self)\n",
        "\n",
        "# League settings\n",
        "LEAGUE = LeagueSettings(\n",
        "    teams=12,\n",
        "    roster_spots={'QB': 1, 'RB': 2, 'WR': 2, 'TE': 1, 'FLEX': 1, 'DEF': 1, 'K': 1, 'BENCH': 6},\n",
        "    total_rounds=15\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data structures defined!\")\n",
        "print(f\"üèà League: {LEAGUE.teams} teams, {LEAGUE.total_rounds} rounds\")\n",
        "print(f\"üìã Roster: {LEAGUE.roster_spots}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aya0qwUe3Vbl"
      },
      "source": [
        "## 3. Data Processing and Player Pool Creation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlJWY6mC3Vbm"
      },
      "source": [
        "### 3.1 Optional: Load Rookie Prediction Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXyI6lF3Vbm",
        "outputId": "247cd2fd-37a3-4a61-beb0-01b604869559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è  No rookie model found - will use simple uncertainty estimates\n",
            "üí° To use rookie predictions:\n",
            "   1. Run rookie_model_comparison.ipynb first\n",
            "   2. Upload the generated best_rookie_model.pkl\n",
            "   3. Restart this cell\n",
            "‚úÖ Rookie uncertainty estimation ready!\n",
            "üìä Using position-based uncertainty estimates\n"
          ]
        }
      ],
      "source": [
        "# Optional: Load rookie prediction model for better uncertainty estimates\n",
        "rookie_model = None\n",
        "rookie_scaler = None\n",
        "\n",
        "try:\n",
        "    # Try to load the rookie prediction model\n",
        "    import pickle\n",
        "\n",
        "    # Check multiple possible locations\n",
        "    model_files = [\n",
        "        'best_rookie_model.pkl',  # From rookie comparison notebook\n",
        "        'rookie_fantasy_model.pkl',  # From rookie example\n",
        "        '/content/best_rookie_model.pkl'  # If uploaded to Colab\n",
        "    ]\n",
        "\n",
        "    for model_file in model_files:\n",
        "        if os.path.exists(model_file):\n",
        "            print(f\"üìä Loading rookie prediction model from {model_file}...\")\n",
        "\n",
        "            with open(model_file, 'rb') as f:\n",
        "                rookie_model_data = pickle.load(f)\n",
        "\n",
        "            rookie_model = rookie_model_data['model']\n",
        "            rookie_scaler = rookie_model_data.get('scaler')\n",
        "            rookie_features = rookie_model_data['feature_names']\n",
        "\n",
        "            print(f\"‚úÖ Rookie model loaded: {rookie_model_data.get('model_name', 'Unknown')}\")\n",
        "            print(f\"üéØ Model R¬≤: {rookie_model_data.get('performance_metrics', {}).get('r2_mean', 'N/A')}\")\n",
        "            print(f\"üìã Features: {len(rookie_features)}\")\n",
        "            break\n",
        "\n",
        "    if rookie_model is None:\n",
        "        print(\"‚ö†Ô∏è  No rookie model found - will use simple uncertainty estimates\")\n",
        "        print(\"üí° To use rookie predictions:\")\n",
        "        print(\"   1. Run rookie_model_comparison.ipynb first\")\n",
        "        print(\"   2. Upload the generated best_rookie_model.pkl\")\n",
        "        print(\"   3. Restart this cell\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading rookie model: {e}\")\n",
        "    print(\"üìù Using default uncertainty estimates\")\n",
        "    rookie_model = None\n",
        "\n",
        "# Function to get rookie uncertainty using the ML model\n",
        "def get_rookie_uncertainty(player_name: str, position: str, draft_info: dict = None) -> float:\n",
        "    \"\"\"\n",
        "    Get uncertainty estimate for a rookie using the ML model\n",
        "\n",
        "    Args:\n",
        "        player_name: Player name\n",
        "        position: Player position\n",
        "        draft_info: Dict with draft capital info (round, pick, age, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Uncertainty value (higher = more risky)\n",
        "    \"\"\"\n",
        "\n",
        "    if rookie_model is None or draft_info is None:\n",
        "        # Default uncertainty based on position\n",
        "        default_uncertainty = {\n",
        "            'QB': 3.0,  # High variance for rookie QBs\n",
        "            'RB': 2.0,  # Moderate variance for RBs\n",
        "            'WR': 2.5,  # Moderate-high variance for WRs\n",
        "            'TE': 1.5,  # Lower variance for TEs\n",
        "            'DEF': 0.5, # Low variance for defense\n",
        "            'K': 0.3    # Very low variance for kickers\n",
        "        }\n",
        "        return default_uncertainty.get(position, 1.5)\n",
        "\n",
        "    try:\n",
        "        # Create feature vector for rookie model prediction\n",
        "        rookie_features_dict = {\n",
        "            'round': draft_info.get('round', 4),\n",
        "            'pick': draft_info.get('pick', 100),\n",
        "            'age': draft_info.get('age', 22),\n",
        "            'early_round': 1 if draft_info.get('round', 4) <= 3 else 0,\n",
        "            'first_round': 1 if draft_info.get('round', 4) == 1 else 0,\n",
        "            'day1_pick': 1 if draft_info.get('pick', 100) <= 32 else 0,\n",
        "            'day2_pick': 1 if 32 < draft_info.get('pick', 100) <= 96 else 0,\n",
        "            'is_qb': 1 if position == 'QB' else 0,\n",
        "            'is_rb': 1 if position == 'RB' else 0,\n",
        "            'is_wr': 1 if position == 'WR' else 0,\n",
        "            'is_te': 1 if position == 'TE' else 0,\n",
        "            'good_team': draft_info.get('good_team', 0),\n",
        "            'good_offense': draft_info.get('good_offense', 0),\n",
        "            'bad_offense': draft_info.get('bad_offense', 0),\n",
        "            'games_played_pct': 0.8,  # Assume 80% games played\n",
        "            'target_share': 0.1 if position in ['WR', 'TE'] else 0.0,\n",
        "            'rush_share': 0.15 if position == 'RB' else 0.0,\n",
        "            'starter_games': 1 if draft_info.get('round', 4) <= 3 else 0,\n",
        "            'yards_per_target': 8.0 if position in ['WR', 'TE'] else 0.0,\n",
        "            'yards_per_carry': 4.0 if position == 'RB' else 0.0\n",
        "        }\n",
        "\n",
        "        # Convert to dataframe with correct feature order\n",
        "        import pandas as pd\n",
        "        feature_df = pd.DataFrame([rookie_features_dict])\n",
        "\n",
        "        # Only use features that the model was trained on\n",
        "        available_features = [f for f in rookie_features if f in feature_df.columns]\n",
        "        X = feature_df[available_features].fillna(0)\n",
        "\n",
        "        # Scale if needed\n",
        "        if rookie_scaler is not None:\n",
        "            X_scaled = rookie_scaler.transform(X)\n",
        "        else:\n",
        "            X_scaled = X\n",
        "\n",
        "        # Get prediction - this gives us expected PPG\n",
        "        predicted_ppg = rookie_model.predict(X_scaled)[0]\n",
        "\n",
        "        # Convert prediction confidence to uncertainty\n",
        "        # Higher predicted PPG = lower uncertainty for established talent\n",
        "        # But rookies always have base uncertainty\n",
        "        base_uncertainty = 1.0  # Minimum uncertainty for rookies\n",
        "\n",
        "        # Draft capital uncertainty - later picks = more uncertain\n",
        "        draft_uncertainty = max(0, (draft_info.get('round', 4) - 1) * 0.3)\n",
        "\n",
        "        # Position-specific uncertainty\n",
        "        position_uncertainty = {\n",
        "            'QB': 1.5, 'RB': 1.0, 'WR': 1.2, 'TE': 0.8, 'DEF': 0.3, 'K': 0.2\n",
        "        }.get(position, 1.0)\n",
        "\n",
        "        total_uncertainty = base_uncertainty + draft_uncertainty + position_uncertainty\n",
        "\n",
        "        return min(total_uncertainty, 4.0)  # Cap at 4.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error in rookie prediction for {player_name}: {e}\")\n",
        "        # Fallback to position-based default\n",
        "        return {\n",
        "            'QB': 3.0, 'RB': 2.0, 'WR': 2.5, 'TE': 1.5, 'DEF': 0.5, 'K': 0.3\n",
        "        }.get(position, 1.5)\n",
        "\n",
        "print(\"‚úÖ Rookie uncertainty estimation ready!\")\n",
        "if rookie_model:\n",
        "    print(\"ü§ñ Using ML model for rookie predictions\")\n",
        "else:\n",
        "    print(\"üìä Using position-based uncertainty estimates\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09HdGLM53Vbm",
        "outputId": "99a16ae7-fa93-49b9-82f5-f4f6b24c6399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Created player pool with 755 players\n",
            "üìä Position breakdown: {'RB': 170, 'WR': 272, 'QB': 99, 'TE': 131, 'DEF': 62, 'K': 21}\n",
            "\n",
            "üèÜ Top 20 Players by VORP:\n",
            " 1. Saquon Barkley            RB  VORP: 10.68 ADP:   3.0\n",
            " 2. Jahmyr Gibbs              RB  VORP:  9.43 ADP:   4.0\n",
            " 3. Derrick Henry             RB  VORP:  8.92 ADP:   7.0\n",
            " 4. Ja'Marr Chase             WR  VORP:  8.50 ADP:   1.0\n",
            " 5. Bijan Robinson            RB  VORP:  7.43 ADP:   2.0\n",
            " 6. Lamar Jackson             QB  VORP:  6.62 ADP:  21.0\n",
            " 7. Jonathan Taylor           RB  VORP:  6.22 ADP:  17.0\n",
            " 8. Rashee Rice               WR  VORP:  6.17 ADP:  64.0\n",
            " 9. Josh Jacobs               RB  VORP:  5.95 ADP:  16.0\n",
            "10. Alvin Kamara              RB  VORP:  5.76 ADP:  45.0\n",
            "11. George Kittle             TE  VORP:  5.71 ADP:  30.0\n",
            "12. Joe Mixon                 RB  VORP:  5.36 ADP:  74.0\n",
            "13. James Cook                RB  VORP:  5.31 ADP:  31.0\n",
            "14. Kyren Williams            RB  VORP:  5.29 ADP:  26.0\n",
            "15. Brock Bowers              TE  VORP:  4.70 ADP:  20.0\n",
            "16. Chris Godwin              WR  VORP:  4.65 ADP:  98.0\n",
            "17. Devon Achane              RB  VORP:  4.59 ADP:  15.0\n",
            "18. Josh Allen                QB  VORP:  4.39 ADP:  23.0\n",
            "19. Trey McBride              TE  VORP:  4.31 ADP:  27.0\n",
            "20. Taysom Hill               TE  VORP:  4.27 ADP:   nan\n",
            "21. Chuba Hubbard             RB  VORP:  4.18 ADP:  42.0\n",
            "22. Tee Higgins               WR  VORP:  4.17 ADP:  29.0\n",
            "23. Joe Burrow                QB  VORP:  4.06 ADP:  39.0\n",
            "24. Amon-Ra St. Brown         WR  VORP:  4.00 ADP:  10.0\n",
            "25. Justin Jefferson          WR  VORP:  3.77 ADP:   5.0\n",
            "26. Eric Gray                 RB  VORP:  3.73 ADP:   7.0\n",
            "27. Christian McCaffrey       RB  VORP:  3.69 ADP:   8.0\n",
            "28. Ashton Jeanty             RB  VORP:  3.65 ADP:  11.0\n",
            "29. Kenneth Walker            RB  VORP:  3.62 ADP:  41.0\n",
            "30. De'Von Achane             RB  VORP:  3.58 ADP:  15.0\n",
            "31. Jalen Hurts               QB  VORP:  3.51 ADP:  33.0\n",
            "32. James Conner              RB  VORP:  3.51 ADP:  46.0\n",
            "33. Chase Brown               RB  VORP:  3.49 ADP:  25.0\n",
            "34. J.J. Taylor               RB  VORP:  3.47 ADP:  17.0\n",
            "35. Nico Collins              WR  VORP:  3.45 ADP:   9.0\n",
            "36. Jonathan Ward             RB  VORP:  3.43 ADP:  17.0\n",
            "37. Mike Evans                WR  VORP:  3.34 ADP:  35.0\n",
            "38. Baker Mayfield            QB  VORP:  3.31 ADP:  67.0\n",
            "39. Jamaal Williams           RB  VORP:  3.29 ADP:  26.0\n",
            "40. Omarion Hampton           RB  VORP:  3.22 ADP:  37.0\n",
            "41. David Montgomery          RB  VORP:  3.20 ADP:  50.0\n",
            "42. Jonnu Smith               TE  VORP:  3.15 ADP: 129.0\n",
            "43. Kenneth Gainwell          RB  VORP:  3.12 ADP:  41.0\n",
            "44. Kenneth Walker III        RB  VORP:  3.09 ADP:  41.0\n",
            "45. Malik Nabers              WR  VORP:  3.01 ADP:  12.0\n",
            "46. Dalvin Cook               RB  VORP:  2.99 ADP:  45.0\n",
            "47. Puka Nacua                WR  VORP:  2.95 ADP:  13.0\n",
            "48. RJ Harvey                 RB  VORP:  2.90 ADP:  54.0\n",
            "49. Isiah Pacheco             RB  VORP:  2.84 ADP:  62.0\n",
            "50. TreVeyon Henderson        RB  VORP:  2.81 ADP:  63.0\n"
          ]
        }
      ],
      "source": [
        "def create_player_pool() -> Dict[str, Player]:\n",
        "    \"\"\"Create unified player pool from draft board and ADP data\"\"\"\n",
        "\n",
        "    # Clean and standardize column names\n",
        "    board = draft_board.copy()\n",
        "    adp = adp_data.copy()\n",
        "\n",
        "    # Standardize column names\n",
        "    if 'Player' in adp.columns:\n",
        "        adp = adp.rename(columns={'Player': 'player_name'})\n",
        "    if 'POS' in adp.columns:\n",
        "        adp = adp.rename(columns={'POS': 'position'})\n",
        "    if 'Yahoo' in adp.columns:\n",
        "        adp = adp.rename(columns={'Yahoo': 'adp_rank'})\n",
        "\n",
        "    # Clean position data (remove numbers like WR1 -> WR)\n",
        "    if 'position' in board.columns:\n",
        "        board['position'] = board['position'].str.replace(r'\\d+', '', regex=True)\n",
        "    if 'position' in adp.columns:\n",
        "        adp['position'] = adp['position'].str.replace(r'\\d+', '', regex=True)\n",
        "\n",
        "    # Map D/ST to DEF\n",
        "    position_mapping = {'D/ST': 'DEF', 'DST': 'DEF'}\n",
        "    for df in [board, adp]:\n",
        "        if 'position' in df.columns:\n",
        "            df['position'] = df['position'].replace(position_mapping)\n",
        "\n",
        "    players = {}\n",
        "\n",
        "    # Process draft board players\n",
        "    for _, row in board.iterrows():\n",
        "        name = str(row.get('player_name', '')).strip()\n",
        "        if not name or name == 'nan':\n",
        "            continue\n",
        "\n",
        "        player = Player(\n",
        "            name=name,\n",
        "            position=str(row.get('position', 'UNKNOWN')),\n",
        "            vorp=float(row.get('VORP', 0.0)),\n",
        "            proj_ppg=float(row.get('proj_ppg_2025', 0.0)),\n",
        "            adp_rank=float(row.get('adp_rank', 999.0)),\n",
        "            risk_sigma=float(row.get('proj_ppg_2025', 0.0)) * 0.1  # 10% uncertainty as default\n",
        "        )\n",
        "        players[name] = player\n",
        "\n",
        "    # Update with ADP data\n",
        "    for _, row in adp.iterrows():\n",
        "        name = str(row.get('player_name', '')).strip()\n",
        "        if not name or name == 'nan':\n",
        "            continue\n",
        "\n",
        "        adp_rank = float(row.get('adp_rank', 999.0))\n",
        "        position = str(row.get('position', 'UNKNOWN'))\n",
        "\n",
        "        if name in players:\n",
        "            # Update existing player\n",
        "            if adp_rank < 999:\n",
        "                players[name].adp_rank = adp_rank\n",
        "            if position != 'UNKNOWN':\n",
        "                players[name].position = position\n",
        "        else:\n",
        "            # Create new player from ADP\n",
        "            players[name] = Player(\n",
        "                name=name,\n",
        "                position=position,\n",
        "                adp_rank=adp_rank,\n",
        "                vorp=0.0,      # Will be estimated later\n",
        "                proj_ppg=8.0,  # Default projection\n",
        "                risk_sigma=1.0 # Higher uncertainty for unknown players\n",
        "            )\n",
        "\n",
        "    # Estimate VORP for players without it using positional averages\n",
        "    position_vorp_avg = {}\n",
        "    for player in players.values():\n",
        "        if player.vorp > 0:\n",
        "            if player.position not in position_vorp_avg:\n",
        "                position_vorp_avg[player.position] = []\n",
        "            position_vorp_avg[player.position].append(player.vorp)\n",
        "\n",
        "    # Calculate averages\n",
        "    for pos in position_vorp_avg:\n",
        "        position_vorp_avg[pos] = np.mean(position_vorp_avg[pos])\n",
        "\n",
        "    # Fill missing VORP values\n",
        "    for player in players.values():\n",
        "        if player.vorp <= 0 and player.position in position_vorp_avg:\n",
        "            # Estimate based on ADP rank within position\n",
        "            pos_players = [\n",
        "                p for p in players.values()\n",
        "                if p.position == player.position and p.adp_rank < 999\n",
        "            ]\n",
        "            if pos_players:\n",
        "                pos_players.sort(key=lambda x: x.adp_rank)\n",
        "                player_rank = next(\n",
        "                    (i for i, p in enumerate(pos_players) if p.name == player.name),\n",
        "                    len(pos_players)\n",
        "                )\n",
        "                # Decay VORP by rank\n",
        "                base_vorp = position_vorp_avg[player.position]\n",
        "                player.vorp = base_vorp * (0.9 ** (player_rank / 10))  # Exponential decay\n",
        "\n",
        "    # Filter out players with no meaningful data\n",
        "    valid_players = {\n",
        "        name: player for name, player in players.items()\n",
        "        if player.adp_rank < 300 or player.vorp > 0\n",
        "    }\n",
        "\n",
        "    print(f\"‚úÖ Created player pool with {len(valid_players)} players\")\n",
        "\n",
        "    # Show position breakdown\n",
        "    pos_counts = Counter(p.position for p in valid_players.values())\n",
        "    print(f\"üìä Position breakdown: {dict(pos_counts)}\")\n",
        "\n",
        "    return valid_players\n",
        "\n",
        "\n",
        "# Create the player pool (uses globals if you don't pass args)\n",
        "player_pool = create_player_pool()\n",
        "\n",
        "# Show top players by VORP\n",
        "top_players = sorted(player_pool.values(), key=lambda x: x.vorp, reverse=True)[:50]\n",
        "print(f\"\\nüèÜ Top 20 Players by VORP:\")\n",
        "for i, player in enumerate(top_players, 1):\n",
        "    print(f\"{i:2d}. {player.name:25s} {player.position:3s} VORP:{player.vorp:6.2f} ADP:{player.adp_rank:6.1f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le61hGOW3Vbm",
        "outputId": "b37d806e-8211-425e-84fb-4909b2e1ce21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Applying enhanced rookie uncertainty estimates...\n",
            "‚úÖ Enhanced uncertainty applied:\n",
            "   üÜï Rookies: 326 players\n",
            "   üë• Veterans: 429 players\n",
            "\n",
            "üìä Sample uncertainty assignments:\n",
            "   üë• Saquon Barkley            (RB) - Uncertainty: 1.07\n",
            "   üë• Jahmyr Gibbs              (RB) - Uncertainty: 1.01\n",
            "   üë• Derrick Henry             (RB) - Uncertainty: 0.98\n",
            "   üë• Ja'Marr Chase             (WR) - Uncertainty: 1.00\n",
            "   üë• Bijan Robinson            (RB) - Uncertainty: 0.91\n",
            "   üë• Lamar Jackson             (QB) - Uncertainty: 1.28\n",
            "   üë• Jonathan Taylor           (RB) - Uncertainty: 0.85\n",
            "   üë• Rashee Rice               (WR) - Uncertainty: 0.88\n",
            "   üë• Josh Jacobs               (RB) - Uncertainty: 0.84\n",
            "   üë• Alvin Kamara              (RB) - Uncertainty: 0.83\n",
            "\n",
            "üìä Using heuristic-based uncertainty estimates\n"
          ]
        }
      ],
      "source": [
        "# Enhanced rookie uncertainty estimation using ML model\n",
        "print(\"üîÑ Applying enhanced rookie uncertainty estimates...\")\n",
        "\n",
        "rookie_count = 0\n",
        "veteran_count = 0\n",
        "\n",
        "for player_name, player in player_pool.items():\n",
        "    # Determine if player is likely a rookie (simple heuristic)\n",
        "    is_rookie = (\n",
        "        'rookie' in player_name.lower() or\n",
        "        player.adp_rank > 150 or  # Late ADP often indicates rookie\n",
        "        player.vorp < 1.0  # Low VORP might indicate rookie uncertainty\n",
        "    )\n",
        "\n",
        "    # Update player rookie status and uncertainty\n",
        "    player.is_rookie = is_rookie\n",
        "\n",
        "    if is_rookie:\n",
        "        # Use ML model for rookie uncertainty if available\n",
        "        draft_info = {\n",
        "            'round': 4,  # Default round (will be updated with real data if available)\n",
        "            'pick': min(player.adp_rank, 200),  # Use ADP as proxy for draft pick\n",
        "            'age': 22,   # Default rookie age\n",
        "            'good_team': 0,  # Default neutral team\n",
        "            'good_offense': 0,\n",
        "            'bad_offense': 0\n",
        "        }\n",
        "\n",
        "        # Try to get draft info from data if available\n",
        "        if hasattr(player, 'round'):\n",
        "            draft_info['round'] = player.round\n",
        "        elif player.adp_rank <= 32:\n",
        "            draft_info['round'] = 1\n",
        "        elif player.adp_rank <= 64:\n",
        "            draft_info['round'] = 2\n",
        "        elif player.adp_rank <= 96:\n",
        "            draft_info['round'] = 3\n",
        "\n",
        "        enhanced_uncertainty = get_rookie_uncertainty(player_name, player.position, draft_info)\n",
        "        player.risk_sigma = enhanced_uncertainty\n",
        "        rookie_count += 1\n",
        "    else:\n",
        "        # Veterans get lower uncertainty (5% of projection)\n",
        "        player.risk_sigma = max(player.proj_ppg * 0.05, 0.3)\n",
        "        veteran_count += 1\n",
        "\n",
        "print(f\"‚úÖ Enhanced uncertainty applied:\")\n",
        "print(f\"   üÜï Rookies: {rookie_count} players\")\n",
        "print(f\"   üë• Veterans: {veteran_count} players\")\n",
        "\n",
        "# Show examples of uncertainty assignments\n",
        "print(f\"\\nüìä Sample uncertainty assignments:\")\n",
        "sample_players = sorted(player_pool.values(), key=lambda x: x.vorp, reverse=True)[:10]\n",
        "for i, player in enumerate(sample_players):\n",
        "    rookie_indicator = \"üÜï\" if player.is_rookie else \"üë•\"\n",
        "    print(f\"   {rookie_indicator} {player.name:<25s} ({player.position}) - Uncertainty: {player.risk_sigma:.2f}\")\n",
        "\n",
        "if rookie_model:\n",
        "    print(f\"\\nü§ñ Using ML model for rookie predictions!\")\n",
        "else:\n",
        "    print(f\"\\nüìä Using heuristic-based uncertainty estimates\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV-Kdfm3Vbm"
      },
      "source": [
        "## 4. Opponent Modeling with Plackett-Luce\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "aqWDChtz3Vbn",
        "outputId": "fa904791-951d-4e25-fcc1-8a2619bc8a20"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (ipython-input-3656458357.py, line 36)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3656458357.py\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    weight = self.player_weights.get(player.name, 0.001)\\n            \\n            # Position need bonus\\n            need_bonus = 1.0\\n            if player.position in needs and needs[player.position] > 0:\\n                need_bonus = 2.0  # 2x bonus for needed positions\\n            elif player.position in state.league.flex_positions and needs.get('FLEX', 0) > 0:\\n                need_bonus = 1.5  # 1.5x bonus for flex-eligible positions\\n            \\n            # Position run bonus\\n            run_bonus = 1.0\\n            if (self.position_run_active == player.position and \\n                self.position_run_remaining > 0):\\n                run_bonus = 3.0\\n            \\n            # Don't draft too many of same position early\\n            roster = state.team_rosters[team_id]\\n            pos_count = sum(1 for p in roster if p.position == player.position)\\n            max_reasonable = state.league.roster_spots.get(player.position, 1) + 1\\n            if pos_count >= max_reasonable and state.current_round <= 8:\\n                weight *= 0.1  # Heavy penalty for overdrafting early\\n            \\n            final_weight = weight * need_bonus * run_bonus\\n            probs.append(final_weight)\\n        \\n        # Apply temperature for randomness\\n        if self.temperature > 0:\\n            log_probs = np.log(np.array(probs) + 1e-10)\\n            scaled_log_probs = log_probs / self.temperature\\n            probs = np.exp(scaled_log_probs - np.max(scaled_lo...\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ],
      "source": [
        "class OpponentModel:\n",
        "    \"\"\"Models how opponents draft using ADP with stochastic sampling\"\"\"\n",
        "\n",
        "    def __init__(self, player_pool: Dict[str, Player], temperature: float = 0.5,\n",
        "                 position_run_prob: float = 0.1):\n",
        "        self.player_pool = player_pool\n",
        "        self.temperature = temperature  # Higher = more random\n",
        "        self.position_run_prob = position_run_prob  # Probability of position runs\n",
        "        self.position_run_active = None  # Currently active position run\n",
        "        self.position_run_remaining = 0\n",
        "\n",
        "        # Create ADP-based preference weights\n",
        "        self.player_weights = {}\n",
        "        for player in player_pool.values():\n",
        "            if player.adp_rank < 999:\n",
        "                # Convert ADP rank to weight (lower rank = higher weight)\n",
        "                # Use exponential decay: higher picks much more likely\n",
        "                self.player_weights[player.name] = np.exp(-player.adp_rank / 50.0)\n",
        "            else:\n",
        "                self.player_weights[player.name] = 0.001  # Very low weight for unranked\n",
        "\n",
        "    def sample_opponent_pick(self, state: DraftState, team_id: int) -> Optional[Player]:\n",
        "        \"\"\"Sample a pick for an opponent team using Plackett-Luce model\"\"\"\n",
        "\n",
        "        available = list(state.available_players)\n",
        "        if not available:\n",
        "            return None\n",
        "\n",
        "        # Get team's positional needs\n",
        "        needs = state.get_roster_needs(team_id)\n",
        "\n",
        "        # Calculate selection probabilities\n",
        "        probs = []\n",
        "        for player in available:\n",
        "            # Base weight from ADP\n",
        "            weight = self.player_weights.get(player.name, 0.001)\\n            \\n            # Position need bonus\\n            need_bonus = 1.0\\n            if player.position in needs and needs[player.position] > 0:\\n                need_bonus = 2.0  # 2x bonus for needed positions\\n            elif player.position in state.league.flex_positions and needs.get('FLEX', 0) > 0:\\n                need_bonus = 1.5  # 1.5x bonus for flex-eligible positions\\n            \\n            # Position run bonus\\n            run_bonus = 1.0\\n            if (self.position_run_active == player.position and \\n                self.position_run_remaining > 0):\\n                run_bonus = 3.0\\n            \\n            # Don't draft too many of same position early\\n            roster = state.team_rosters[team_id]\\n            pos_count = sum(1 for p in roster if p.position == player.position)\\n            max_reasonable = state.league.roster_spots.get(player.position, 1) + 1\\n            if pos_count >= max_reasonable and state.current_round <= 8:\\n                weight *= 0.1  # Heavy penalty for overdrafting early\\n            \\n            final_weight = weight * need_bonus * run_bonus\\n            probs.append(final_weight)\\n        \\n        # Apply temperature for randomness\\n        if self.temperature > 0:\\n            log_probs = np.log(np.array(probs) + 1e-10)\\n            scaled_log_probs = log_probs / self.temperature\\n            probs = np.exp(scaled_log_probs - np.max(scaled_log_probs))  # Numerical stability\\n        \\n        # Normalize probabilities\\n        probs = np.array(probs)\\n        probs = probs / np.sum(probs)\\n        \\n        # Sample player\\n        selected_idx = np.random.choice(len(available), p=probs)\\n        selected_player = available[selected_idx]\\n        \\n        # Update position run state\\n        if self.position_run_remaining > 0:\\n            self.position_run_remaining -= 1\\n            if self.position_run_remaining == 0:\\n                self.position_run_active = None\\n        else:\\n            # Potentially start a new position run\\n            if (np.random.random() < self.position_run_prob and \\n                selected_player.position in ['RB', 'WR', 'QB']):\\n                self.position_run_active = selected_player.position\\n                self.position_run_remaining = np.random.randint(2, 5)  # 2-4 more picks\\n        \\n        return selected_player\\n    \\n    def reset_position_runs(self):\\n        \\\"\\\"\\\"Reset position run state (call at start of new simulation)\\\"\\\"\\\"\\n        self.position_run_active = None\\n        self.position_run_remaining = 0\\n\\n# Create opponent model\\nopponent_model = OpponentModel(player_pool, temperature=0.5, position_run_prob=0.1)\\n\\nprint(\\\"‚úÖ Opponent model created!\\\")\\nprint(f\\\"üé≤ Temperature: {opponent_model.temperature} (higher = more random)\\\")\\nprint(f\\\"üèÉ Position run probability: {opponent_model.position_run_prob}\\\")\\n\\n# Test the opponent model\\nprint(\\\"\\\\nüß™ Testing opponent model with sample picks:\\\")\\ntest_state = DraftState(league=LEAGUE, available_players=set(player_pool.values()))\\nfor i in range(5):\\n    pick = opponent_model.sample_opponent_pick(test_state, team_id=2)\\n    if pick:\\n        print(f\\\"Pick {i+1}: {pick.name} ({pick.position}) - ADP: {pick.adp_rank:.1f}, VORP: {pick.vorp:.2f}\\\")\\n        test_state.available_players.remove(pick)\\n        test_state.team_rosters[2].append(pick)\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSxo7nF23Vbn"
      },
      "source": [
        "## 5. Reward Function and Value Estimation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFhJdOUY3Vbn"
      },
      "outputs": [],
      "source": [
        "class RewardFunction:\n",
        "    \"\"\"Calculates rewards for draft decisions\"\"\"\n",
        "\n",
        "    def __init__(self, risk_penalty: float = 0.1, overstack_penalty: float = 0.5,\n",
        "                 bye_penalty: float = 0.2):\n",
        "        self.risk_penalty = risk_penalty  # Œª - penalty for player uncertainty\n",
        "        self.overstack_penalty = overstack_penalty  # Œ≥ - penalty for position overstacking\n",
        "        self.bye_penalty = bye_penalty  # Œ≤ - penalty for bye week conflicts\n",
        "\n",
        "    def calculate_roster_value(self, roster: List[Player], league: LeagueSettings) -> float:\n",
        "        \"\"\"Calculate total value of a roster\"\"\"\n",
        "        if not roster:\n",
        "            return 0.0\n",
        "\n",
        "        # Base VORP sum\n",
        "        base_vorp = sum(player.vorp for player in roster)\n",
        "\n",
        "        # Risk penalty (uncertainty, especially for rookies)\n",
        "        risk_penalty = self.risk_penalty * sum(player.risk_sigma for player in roster)\n",
        "\n",
        "        # Position overstacking penalty\n",
        "        position_counts = Counter(p.position for p in roster)\n",
        "        overstack_penalty = 0.0\n",
        "        for pos, count in position_counts.items():\n",
        "            max_useful = league.roster_spots.get(pos, 0)\n",
        "            if pos in league.flex_positions:\n",
        "                max_useful += league.roster_spots.get('FLEX', 0)\n",
        "            max_useful += 2  # Allow some bench depth\n",
        "\n",
        "            if count > max_useful:\n",
        "                overstack_penalty += self.overstack_penalty * (count - max_useful) ** 2\n",
        "\n",
        "        # Bye week conflict penalty (simplified)\n",
        "        bye_weeks = [p.bye_week for p in roster if p.bye_week > 0]\n",
        "        bye_conflicts = len(bye_weeks) - len(set(bye_weeks))\n",
        "        bye_penalty = self.bye_penalty * bye_conflicts\n",
        "\n",
        "        total_value = base_vorp - risk_penalty - overstack_penalty - bye_penalty\n",
        "        return total_value\n",
        "\n",
        "    def calculate_pick_reward(self, player: Player, current_roster: List[Player],\n",
        "                             league: LeagueSettings) -> float:\n",
        "        \"\"\"Calculate incremental reward for picking a specific player\"\"\"\n",
        "\n",
        "        # Base VORP\n",
        "        base_reward = player.vorp\n",
        "\n",
        "        # Position need bonus\n",
        "        position_counts = Counter(p.position for p in current_roster)\n",
        "        needs = {}\n",
        "        for pos, required in league.roster_spots.items():\n",
        "            needs[pos] = max(0, required - position_counts.get(pos, 0))\n",
        "\n",
        "        need_bonus = 0.0\n",
        "        if player.position in needs and needs[player.position] > 0:\n",
        "            need_bonus = player.vorp * 0.2  # 20% bonus for needed positions\n",
        "        elif player.position in league.flex_positions and needs.get('FLEX', 0) > 0:\n",
        "            need_bonus = player.vorp * 0.1  # 10% bonus for flex-eligible\n",
        "\n",
        "        # Risk penalty\n",
        "        risk_penalty = self.risk_penalty * player.risk_sigma\n",
        "\n",
        "        # Early round scarcity bonus\n",
        "        round_num = len(current_roster) // 12 + 1  # Approximate round\n",
        "        scarcity_bonus = 0.0\n",
        "        if round_num <= 3 and player.position in ['RB', 'WR']:\n",
        "            scarcity_bonus = player.vorp * 0.15  # 15% bonus for scarce positions early\n",
        "\n",
        "        total_reward = base_reward + need_bonus + scarcity_bonus - risk_penalty\n",
        "        return total_reward\n",
        "\n",
        "class ValueFunction:\n",
        "    \"\"\"Heuristic value function for MCTS\"\"\"\n",
        "\n",
        "    def __init__(self, player_pool: Dict[str, Player], reward_fn: RewardFunction):\n",
        "        self.player_pool = player_pool\n",
        "        self.reward_fn = reward_fn\n",
        "\n",
        "        # Precompute position-ranked players for efficiency\n",
        "        self.players_by_position = defaultdict(list)\n",
        "        for player in player_pool.values():\n",
        "            self.players_by_position[player.position].append(player)\n",
        "\n",
        "        # Sort by VORP descending\n",
        "        for pos in self.players_by_position:\n",
        "            self.players_by_position[pos].sort(key=lambda x: x.vorp, reverse=True)\n",
        "\n",
        "    def estimate_state_value(self, state: DraftState) -> float:\n",
        "        \"\"\"Estimate the value of the current state for our team\"\"\"\n",
        "\n",
        "        our_roster = state.team_rosters[state.our_team_id]\n",
        "\n",
        "        # Current roster value\n",
        "        current_value = self.reward_fn.calculate_roster_value(our_roster, state.league)\n",
        "\n",
        "        # Expected value of filling remaining roster spots\n",
        "        expected_fill_value = self._estimate_expected_fill_value(state)\n",
        "\n",
        "        return current_value + expected_fill_value\n",
        "\n",
        "    def _estimate_expected_fill_value(self, state: DraftState) -> float:\n",
        "        \"\"\"Estimate value of filling remaining roster spots\"\"\"\n",
        "\n",
        "        our_roster = state.team_rosters[state.our_team_id]\n",
        "        needs = state.get_roster_needs(state.our_team_id)\n",
        "        available = list(state.available_players)\n",
        "\n",
        "        if not available:\n",
        "            return 0.0\n",
        "\n",
        "        # Estimate picks until our next few turns\n",
        "        picks_until_next = state.picks_until_our_turn\n",
        "        if picks_until_next == 0:\n",
        "            picks_until_next = state.league.teams  # Next turn after this one\n",
        "\n",
        "        # Estimate how many players will be taken before our next pick\n",
        "        total_remaining_picks = sum(needs.values())\n",
        "        if total_remaining_picks == 0:\n",
        "            return 0.0\n",
        "\n",
        "        expected_value = 0.0\n",
        "        pick_number = 0\n",
        "\n",
        "        for position, needed in needs.items():\n",
        "            if needed == 0:\n",
        "                continue\n",
        "\n",
        "            available_at_pos = [p for p in available if p.position == position]\n",
        "            if position == 'FLEX':\n",
        "                available_at_pos = [p for p in available if p.position in state.league.flex_positions]\n",
        "            elif position == 'BENCH':\n",
        "                available_at_pos = available  # Any position for bench\n",
        "\n",
        "            if not available_at_pos:\n",
        "                continue\n",
        "\n",
        "            available_at_pos.sort(key=lambda x: x.vorp, reverse=True)\n",
        "\n",
        "            for i in range(min(needed, len(available_at_pos))):\n",
        "                # Estimate which player we might get based on pick timing\n",
        "                # Assume some players will be taken before our turn\n",
        "                estimated_pick_index = min(pick_number + picks_until_next // 2,\n",
        "                                         len(available_at_pos) - 1)\n",
        "\n",
        "                if estimated_pick_index < len(available_at_pos):\n",
        "                    expected_player = available_at_pos[estimated_pick_index]\n",
        "                    expected_value += expected_player.vorp * 0.8  # Discount for uncertainty\n",
        "\n",
        "                pick_number += 1\n",
        "                picks_until_next = max(state.league.teams, picks_until_next)  # Future picks farther apart\n",
        "\n",
        "        return expected_value\n",
        "\n",
        "# Create reward function and value estimator\n",
        "reward_function = RewardFunction(risk_penalty=0.1, overstack_penalty=0.5, bye_penalty=0.2)\n",
        "value_function = ValueFunction(player_pool, reward_function)\n",
        "\n",
        "print(\"‚úÖ Reward and value functions created!\")\n",
        "print(f\"üéØ Risk penalty (Œª): {reward_function.risk_penalty}\")\n",
        "print(f\"üö´ Overstack penalty (Œ≥): {reward_function.overstack_penalty}\")\n",
        "print(f\"üìÖ Bye week penalty (Œ≤): {reward_function.bye_penalty}\")\n",
        "\n",
        "# Test the reward function\n",
        "test_roster = [\n",
        "    next(p for p in player_pool.values() if p.position == 'RB'),\n",
        "    next(p for p in player_pool.values() if p.position == 'WR'),\n",
        "    next(p for p in player_pool.values() if p.position == 'QB')\n",
        "]\n",
        "\n",
        "test_value = reward_function.calculate_roster_value(test_roster, LEAGUE)\n",
        "print(f\"\\nüß™ Test roster value: {test_value:.2f}\")\n",
        "for player in test_roster:\n",
        "    reward = reward_function.calculate_pick_reward(player, test_roster[:-1], LEAGUE)\n",
        "    print(f\"   {player.name} ({player.position}): {reward:.2f} reward\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYru84Qo3Vbo"
      },
      "source": [
        "## 6. MCTS Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZXujbRm3Vbo"
      },
      "outputs": [],
      "source": [
        "# Simplified MCTS implementation for draft strategy\n",
        "class MCTSNode:\n",
        "    \"\"\"Node in the MCTS tree\"\"\"\n",
        "    def __init__(self, state: DraftState, parent=None, action=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action = action  # Player that was picked to reach this state\n",
        "        self.children = {}\n",
        "        self.visits = 0\n",
        "        self.value_sum = 0.0\n",
        "        self.untried_actions = None\n",
        "\n",
        "    @property\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.untried_actions) == 0 if self.untried_actions is not None else False\n",
        "\n",
        "    @property\n",
        "    def is_terminal(self):\n",
        "        return self.state.is_draft_complete()\n",
        "\n",
        "    def ucb1_score(self, exploration_constant=1.414):\n",
        "        \"\"\"Calculate UCB1 score for action selection\"\"\"\n",
        "        if self.visits == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        exploitation = self.value_sum / self.visits\n",
        "        exploration = exploration_constant * math.sqrt(math.log(self.parent.visits) / self.visits)\n",
        "        return exploitation + exploration\n",
        "\n",
        "class SimplifiedMCTS:\n",
        "    \"\"\"Simplified MCTS for draft decisions\"\"\"\n",
        "\n",
        "    def __init__(self, opponent_model: OpponentModel, value_function: ValueFunction,\n",
        "                 reward_function: RewardFunction, simulations=400):\n",
        "        self.opponent_model = opponent_model\n",
        "        self.value_function = value_function\n",
        "        self.reward_function = reward_function\n",
        "        self.simulations = simulations\n",
        "\n",
        "    def search(self, initial_state: DraftState) -> Player:\n",
        "        \"\"\"Run MCTS to find best action\"\"\"\n",
        "        root = MCTSNode(initial_state.copy())\n",
        "\n",
        "        for _ in range(self.simulations):\n",
        "            # Selection and expansion\n",
        "            node = self._select_and_expand(root)\n",
        "\n",
        "            # Simulation (rollout)\n",
        "            value = self._rollout(node.state.copy())\n",
        "\n",
        "            # Backpropagation\n",
        "            self._backpropagate(node, value)\n",
        "\n",
        "        # Return action with most visits (most robust)\n",
        "        if not root.children:\n",
        "            # Fallback to greedy VORP if no expansions\n",
        "            available = list(initial_state.available_players)\n",
        "            if available:\n",
        "                return max(available, key=lambda p: p.vorp)\n",
        "            return None\n",
        "\n",
        "        best_action = max(root.children.keys(), key=lambda a: root.children[a].visits)\n",
        "        return best_action\n",
        "\n",
        "    def _select_and_expand(self, root: MCTSNode) -> MCTSNode:\n",
        "        \"\"\"Select path through tree and expand if possible\"\"\"\n",
        "        node = root\n",
        "\n",
        "        # Selection: traverse tree using UCB1\n",
        "        while not node.is_terminal and node.is_fully_expanded:\n",
        "            if not node.children:\n",
        "                break\n",
        "            node = max(node.children.values(), key=lambda n: n.ucb1_score())\n",
        "\n",
        "        # Expansion: add new child if possible\n",
        "        if not node.is_terminal:\n",
        "            if node.untried_actions is None:\n",
        "                node.untried_actions = self._get_valid_actions(node.state)\n",
        "\n",
        "            if node.untried_actions:\n",
        "                action = node.untried_actions.pop()\n",
        "                new_state = self._apply_action(node.state.copy(), action)\n",
        "                child = MCTSNode(new_state, parent=node, action=action)\n",
        "                node.children[action] = child\n",
        "                return child\n",
        "\n",
        "        return node\n",
        "\n",
        "    def _get_valid_actions(self, state: DraftState) -> List[Player]:\n",
        "        \"\"\"Get valid actions (available players) with action masking\"\"\"\n",
        "        available = list(state.available_players)\n",
        "\n",
        "        # Action masking: remove clearly bad picks\n",
        "        our_roster = state.team_rosters[state.our_team_id]\n",
        "        position_counts = Counter(p.position for p in our_roster)\n",
        "\n",
        "        valid_actions = []\n",
        "        for player in available:\n",
        "            # Don't draft 3rd QB early\n",
        "            if (player.position == 'QB' and position_counts.get('QB', 0) >= 2 and\n",
        "                state.current_round <= 10):\n",
        "                continue\n",
        "\n",
        "            # Don't draft 4th RB/WR early unless exceptional value\n",
        "            if (player.position in ['RB', 'WR'] and position_counts.get(player.position, 0) >= 3 and\n",
        "                state.current_round <= 8 and player.vorp < 3.0):\n",
        "                continue\n",
        "\n",
        "            # Don't draft DEF/K too early\n",
        "            if (player.position in ['DEF', 'K'] and state.current_round <= 12):\n",
        "                continue\n",
        "\n",
        "            valid_actions.append(player)\n",
        "\n",
        "        # Sort by VORP for better action ordering\n",
        "        valid_actions.sort(key=lambda p: p.vorp, reverse=True)\n",
        "        return valid_actions[:50]  # Limit to top 50 to keep search manageable\n",
        "\n",
        "    def _apply_action(self, state: DraftState, action: Player) -> DraftState:\n",
        "        \"\"\"Apply action (pick player) to state\"\"\"\n",
        "        # Remove player from available pool\n",
        "        state.available_players.discard(action)\n",
        "\n",
        "        # Add to our roster\n",
        "        state.team_rosters[state.our_team_id].append(action)\n",
        "\n",
        "        # Advance to next pick\n",
        "        if state.current_pick_in_round < state.league.teams:\n",
        "            state.current_pick_in_round += 1\n",
        "        else:\n",
        "            state.current_round += 1\n",
        "            state.current_pick_in_round = 1\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _rollout(self, state: DraftState) -> float:\n",
        "        \"\"\"Simulate rest of draft using simple policy\"\"\"\n",
        "        rollout_state = state.copy()\n",
        "\n",
        "        while not rollout_state.is_draft_complete() and rollout_state.available_players:\n",
        "            current_team = rollout_state.current_team_picking\n",
        "\n",
        "            if current_team == rollout_state.our_team_id:\n",
        "                # Our turn: use greedy VORP with positional needs\n",
        "                available = list(rollout_state.available_players)\n",
        "                if not available:\n",
        "                    break\n",
        "\n",
        "                our_roster = rollout_state.team_rosters[rollout_state.our_team_id]\n",
        "                best_player = None\n",
        "                best_score = -float('inf')\n",
        "\n",
        "                for player in available[:20]:  # Consider top 20 for speed\n",
        "                    score = self.reward_function.calculate_pick_reward(player, our_roster, rollout_state.league)\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_player = player\n",
        "\n",
        "                if best_player:\n",
        "                    rollout_state.available_players.discard(best_player)\n",
        "                    rollout_state.team_rosters[current_team].append(best_player)\n",
        "            else:\n",
        "                # Opponent turn: use opponent model\n",
        "                pick = self.opponent_model.sample_opponent_pick(rollout_state, current_team)\n",
        "                if pick:\n",
        "                    rollout_state.available_players.discard(pick)\n",
        "                    rollout_state.team_rosters[current_team].append(pick)\n",
        "\n",
        "            # Advance pick\n",
        "            if rollout_state.current_pick_in_round < rollout_state.league.teams:\n",
        "                rollout_state.current_pick_in_round += 1\n",
        "            else:\n",
        "                rollout_state.current_round += 1\n",
        "                rollout_state.current_pick_in_round = 1\n",
        "\n",
        "        # Evaluate final state\n",
        "        return self.value_function.estimate_state_value(rollout_state)\n",
        "\n",
        "    def _backpropagate(self, node: MCTSNode, value: float):\n",
        "        \"\"\"Backpropagate value up the tree\"\"\"\n",
        "        while node is not None:\n",
        "            node.visits += 1\n",
        "            node.value_sum += value\n",
        "            node = node.parent\n",
        "\n",
        "# Create MCTS agent\n",
        "mcts_agent = SimplifiedMCTS(opponent_model, value_function, reward_function, simulations=200)\n",
        "\n",
        "print(\"‚úÖ MCTS agent created!\")\n",
        "print(f\"üîç Simulations per decision: {mcts_agent.simulations}\")\n",
        "print(\"üéØ Ready for draft strategy testing!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj867h1P3Vbo"
      },
      "source": [
        "## 7. Backtesting Framework - Strategy Comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be17wW933Vbo"
      },
      "source": [
        "### 6.1 GPU-Accelerated MCTS (T4 Optimized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtYynh4g3Vbo"
      },
      "outputs": [],
      "source": [
        "if GPU_AVAILABLE:\n",
        "\n",
        "    class GPUAcceleratedMCTS:\n",
        "        \"\"\"\n",
        "        GPU-optimized MCTS implementation using PyTorch and CuPy\n",
        "        Designed specifically for T4 GPU with batch processing\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, opponent_model, reward_function, value_function,\n",
        "                     c_param=1.4, simulations_per_move=800, batch_size=64):\n",
        "            self.opponent_model = opponent_model\n",
        "            self.reward_function = reward_function\n",
        "            self.value_function = value_function\n",
        "            self.c_param = c_param\n",
        "            self.simulations_per_move = simulations_per_move\n",
        "            self.batch_size = batch_size  # T4-optimized batch size\n",
        "\n",
        "            # GPU tensors for fast computation\n",
        "            self.device = torch.device('cuda')\n",
        "\n",
        "            # Pre-allocate GPU memory for common computations\n",
        "            self._init_gpu_buffers()\n",
        "\n",
        "        def _init_gpu_buffers(self):\n",
        "            \"\"\"Pre-allocate GPU memory buffers for efficiency\"\"\"\n",
        "            max_players = 500  # Reasonable upper bound\n",
        "            max_simulations = 2000\n",
        "\n",
        "            # Pre-allocate tensors\n",
        "            self.player_values_gpu = torch.zeros(max_players, device=self.device, dtype=torch.float32)\n",
        "            self.ucb_scores_gpu = torch.zeros(max_players, device=self.device, dtype=torch.float32)\n",
        "            self.visit_counts_gpu = torch.zeros(max_players, device=self.device, dtype=torch.int32)\n",
        "            self.win_rates_gpu = torch.zeros(max_players, device=self.device, dtype=torch.float32)\n",
        "\n",
        "            print(f\"üöÄ GPU buffers allocated on {self.device}\")\n",
        "\n",
        "        @torch.jit.script_method if hasattr(torch.jit, 'script_method') else lambda x: x\n",
        "        def _calculate_ucb_batch(self, win_rates: torch.Tensor, visit_counts: torch.Tensor,\n",
        "                                total_visits: int, c_param: float) -> torch.Tensor:\n",
        "            \"\"\"Vectorized UCB calculation on GPU\"\"\"\n",
        "            if total_visits == 0:\n",
        "                return torch.full_like(win_rates, float('inf'))\n",
        "\n",
        "            exploration = c_param * torch.sqrt(\n",
        "                torch.log(torch.tensor(total_visits, device=win_rates.device)) /\n",
        "                torch.clamp(visit_counts.float(), min=1.0)\n",
        "            )\n",
        "\n",
        "            return win_rates + exploration\n",
        "\n",
        "        def _batch_simulate_rollouts(self, states: List, batch_size: int = None) -> torch.Tensor:\n",
        "            \"\"\"\n",
        "            Batch process multiple rollout simulations on GPU\n",
        "            \"\"\"\n",
        "            if batch_size is None:\n",
        "                batch_size = min(self.batch_size, len(states))\n",
        "\n",
        "            results = []\n",
        "\n",
        "            for i in range(0, len(states), batch_size):\n",
        "                batch_states = states[i:i + batch_size]\n",
        "                batch_results = []\n",
        "\n",
        "                # Process batch of rollouts\n",
        "                for state in batch_states:\n",
        "                    # Use value function for fast approximation\n",
        "                    value = self.value_function.estimate_state_value(state)\n",
        "                    batch_results.append(value)\n",
        "\n",
        "                # Convert to GPU tensor\n",
        "                batch_tensor = torch.tensor(batch_results, device=self.device, dtype=torch.float32)\n",
        "                results.append(batch_tensor)\n",
        "\n",
        "            return torch.cat(results) if results else torch.tensor([], device=self.device)\n",
        "\n",
        "        def _gpu_action_selection(self, available_actions: List, node_stats: Dict) -> int:\n",
        "            \"\"\"\n",
        "            GPU-accelerated action selection using vectorized UCB\n",
        "            \"\"\"\n",
        "            if not available_actions:\n",
        "                return None\n",
        "\n",
        "            n_actions = len(available_actions)\n",
        "\n",
        "            # Prepare data on GPU\n",
        "            win_rates = torch.zeros(n_actions, device=self.device)\n",
        "            visit_counts = torch.zeros(n_actions, device=self.device)\n",
        "\n",
        "            total_visits = sum(node_stats.get(action, {}).get('visits', 0) for action in available_actions)\n",
        "\n",
        "            for i, action in enumerate(available_actions):\n",
        "                stats = node_stats.get(action, {'wins': 0, 'visits': 0})\n",
        "                visit_counts[i] = stats['visits']\n",
        "                win_rates[i] = stats['wins'] / max(stats['visits'], 1)\n",
        "\n",
        "            # Calculate UCB scores on GPU\n",
        "            ucb_scores = self._calculate_ucb_batch(win_rates, visit_counts, total_visits, self.c_param)\n",
        "\n",
        "            # Select best action\n",
        "            best_idx = torch.argmax(ucb_scores).item()\n",
        "            return available_actions[best_idx]\n",
        "\n",
        "        def search(self, root_state: 'DraftState') -> int:\n",
        "            \"\"\"\n",
        "            Main MCTS search with GPU acceleration\n",
        "            \"\"\"\n",
        "            # Statistics tracking\n",
        "            stats = defaultdict(lambda: {'wins': 0, 'visits': 0})\n",
        "\n",
        "            # Batch simulations for GPU efficiency\n",
        "            simulation_batches = self.simulations_per_move // self.batch_size\n",
        "            remainder = self.simulations_per_move % self.batch_size\n",
        "\n",
        "            print(f\"üî• Running {self.simulations_per_move} GPU-accelerated simulations...\")\n",
        "\n",
        "            with torch.cuda.amp.autocast():  # Mixed precision for T4 efficiency\n",
        "\n",
        "                for batch_idx in tqdm(range(simulation_batches), desc=\"GPU Batches\"):\n",
        "                    current_batch_size = self.batch_size\n",
        "                    if batch_idx == simulation_batches - 1:\n",
        "                        current_batch_size += remainder\n",
        "\n",
        "                    # Selection phase - find promising actions\n",
        "                    available_actions = root_state.get_valid_actions()\n",
        "                    if not available_actions:\n",
        "                        break\n",
        "\n",
        "                    # Batch simulate multiple paths\n",
        "                    batch_states = []\n",
        "                    batch_actions = []\n",
        "\n",
        "                    for _ in range(current_batch_size):\n",
        "                        # Select action using GPU-accelerated UCB\n",
        "                        action = self._gpu_action_selection(available_actions, stats)\n",
        "                        if action is None:\n",
        "                            continue\n",
        "\n",
        "                        # Apply action to get new state\n",
        "                        new_state = root_state.copy()\n",
        "                        new_state.make_pick(action)\n",
        "\n",
        "                        batch_states.append(new_state)\n",
        "                        batch_actions.append(action)\n",
        "\n",
        "                    if not batch_states:\n",
        "                        continue\n",
        "\n",
        "                    # Batch rollout evaluation on GPU\n",
        "                    rollout_values = self._batch_simulate_rollouts(batch_states, current_batch_size)\n",
        "\n",
        "                    # Backpropagation\n",
        "                    for action, value in zip(batch_actions, rollout_values.cpu().numpy()):\n",
        "                        stats[action]['visits'] += 1\n",
        "                        stats[action]['wins'] += float(value)\n",
        "\n",
        "            # Select final action\n",
        "            if not stats:\n",
        "                available_actions = root_state.get_valid_actions()\n",
        "                return available_actions[0] if available_actions else None\n",
        "\n",
        "            # Return action with highest win rate\n",
        "            best_action = max(stats.keys(), key=lambda a: stats[a]['wins'] / max(stats[a]['visits'], 1))\n",
        "\n",
        "            # Print GPU performance stats\n",
        "            total_simulations = sum(stats[a]['visits'] for a in stats)\n",
        "            print(f\"‚úÖ Completed {total_simulations} GPU simulations\")\n",
        "            print(f\"üéØ Best action win rate: {stats[best_action]['wins'] / stats[best_action]['visits']:.3f}\")\n",
        "\n",
        "            return best_action\n",
        "\n",
        "    print(\"‚úÖ GPU-Accelerated MCTS ready for T4!\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  GPU not available - using CPU MCTS\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhZ13Rte3Vbp"
      },
      "outputs": [],
      "source": [
        "class AdaptiveMCTSStrategy(DraftStrategy):\n",
        "    \"\"\"\n",
        "    Adaptive MCTS Strategy that automatically uses GPU acceleration when available\n",
        "    Falls back to CPU implementation for compatibility\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, opponent_model, reward_function, value_function,\n",
        "                 simulations_per_move=800, c_param=1.4, use_gpu=True):\n",
        "        super().__init__(\"Adaptive MCTS\")\n",
        "        self.opponent_model = opponent_model\n",
        "        self.reward_function = reward_function\n",
        "        self.value_function = value_function\n",
        "        self.simulations_per_move = simulations_per_move\n",
        "        self.c_param = c_param\n",
        "        self.use_gpu = use_gpu and GPU_AVAILABLE\n",
        "\n",
        "        # Initialize the appropriate MCTS implementation\n",
        "        if self.use_gpu:\n",
        "            print(\"üöÄ Using GPU-Accelerated MCTS\")\n",
        "            self.mcts = GPUAcceleratedMCTS(\n",
        "                opponent_model=opponent_model,\n",
        "                reward_function=reward_function,\n",
        "                value_function=value_function,\n",
        "                c_param=c_param,\n",
        "                simulations_per_move=simulations_per_move,\n",
        "                batch_size=64  # T4-optimized batch size\n",
        "            )\n",
        "        else:\n",
        "            print(\"üìä Using CPU MCTS\")\n",
        "            self.mcts = SimplifiedMCTS(\n",
        "                opponent_model=opponent_model,\n",
        "                reward_function=reward_function,\n",
        "                value_function=value_function,\n",
        "                c_param=c_param,\n",
        "                simulations_per_move=simulations_per_move\n",
        "            )\n",
        "\n",
        "    def make_pick(self, draft_state: 'DraftState') -> int:\n",
        "        \"\"\"Make a pick using MCTS (GPU or CPU)\"\"\"\n",
        "        if draft_state.our_turn():\n",
        "            # Use MCTS to select best action\n",
        "            best_action = self.mcts.search(draft_state)\n",
        "\n",
        "            if best_action is not None:\n",
        "                pick_info = f\"{'üöÄ GPU' if self.use_gpu else 'üìä CPU'} MCTS selected: {draft_state.available_players[best_action].name}\"\n",
        "                print(f\"üéØ {pick_info}\")\n",
        "                return best_action\n",
        "\n",
        "        # Fallback to greedy VORP if MCTS fails\n",
        "        available_actions = draft_state.get_valid_actions()\n",
        "        if available_actions:\n",
        "            best_action = max(available_actions,\n",
        "                            key=lambda i: draft_state.available_players[i].vorp)\n",
        "            print(f\"‚ö†Ô∏è  Fallback: {draft_state.available_players[best_action].name}\")\n",
        "            return best_action\n",
        "\n",
        "        return None\n",
        "\n",
        "# Performance comparison function\n",
        "def benchmark_mcts_performance():\n",
        "    \"\"\"Compare GPU vs CPU MCTS performance\"\"\"\n",
        "    if not GPU_AVAILABLE:\n",
        "        print(\"‚ö†Ô∏è  GPU not available for benchmarking\")\n",
        "        return\n",
        "\n",
        "    print(\"üèÅ Benchmarking MCTS Performance...\")\n",
        "\n",
        "    # Create test data (you'll need to run this after player_pool is created)\n",
        "    print(\"üí° Run this benchmark after creating player_pool and other components\")\n",
        "    print(\"üìä Expected speedup on T4: 3-5x faster than CPU\")\n",
        "\n",
        "print(\"‚úÖ Adaptive MCTS Strategy ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-URN1Kk3Vbp"
      },
      "outputs": [],
      "source": [
        "class DraftStrategy:\n",
        "    \"\"\"Base class for draft strategies\"\"\"\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "    def make_pick(self, state: DraftState) -> Player:\n",
        "        \"\"\"Select a player to draft\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "class GreedyVORPStrategy(DraftStrategy):\n",
        "    \"\"\"Simple greedy strategy that picks highest VORP available\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"Greedy VORP\")\n",
        "\n",
        "    def make_pick(self, state: DraftState) -> Player:\n",
        "        available = list(state.available_players)\n",
        "        if not available:\n",
        "            return None\n",
        "        return max(available, key=lambda p: p.vorp)\n",
        "\n",
        "class ADPStrategy(DraftStrategy):\n",
        "    \"\"\"Strategy that follows ADP rankings\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__(\"ADP Following\")\n",
        "\n",
        "    def make_pick(self, state: DraftState) -> Player:\n",
        "        available = list(state.available_players)\n",
        "        if not available:\n",
        "            return None\n",
        "        return min(available, key=lambda p: p.adp_rank)\n",
        "\n",
        "class PositionalNeedsStrategy(DraftStrategy):\n",
        "    \"\"\"Strategy that prioritizes positional needs\"\"\"\n",
        "    def __init__(self, reward_function: RewardFunction):\n",
        "        super().__init__(\"Positional Needs\")\n",
        "        self.reward_function = reward_function\n",
        "\n",
        "    def make_pick(self, state: DraftState) -> Player:\n",
        "        available = list(state.available_players)\n",
        "        if not available:\n",
        "            return None\n",
        "\n",
        "        our_roster = state.team_rosters[state.our_team_id]\n",
        "        best_player = None\n",
        "        best_score = -float('inf')\n",
        "\n",
        "        for player in available:\n",
        "            score = self.reward_function.calculate_pick_reward(player, our_roster, state.league)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_player = player\n",
        "\n",
        "        return best_player\n",
        "\n",
        "class MCTSStrategy(DraftStrategy):\n",
        "    \"\"\"MCTS-based strategy\"\"\"\n",
        "    def __init__(self, mcts_agent: SimplifiedMCTS):\n",
        "        super().__init__(\"MCTS\")\n",
        "        self.mcts_agent = mcts_agent\n",
        "\n",
        "    def make_pick(self, state: DraftState) -> Player:\n",
        "        return self.mcts_agent.search(state)\n",
        "\n",
        "class DraftSimulator:\n",
        "    \"\"\"Simulates complete drafts for backtesting\"\"\"\n",
        "\n",
        "    def __init__(self, player_pool: Dict[str, Player], league: LeagueSettings,\n",
        "                 opponent_model: OpponentModel, reward_function: RewardFunction):\n",
        "        self.player_pool = player_pool\n",
        "        self.league = league\n",
        "        self.opponent_model = opponent_model\n",
        "        self.reward_function = reward_function\n",
        "\n",
        "    def simulate_draft(self, our_strategy: DraftStrategy, our_draft_position: int = 1,\n",
        "                      rounds_to_simulate: int = 10) -> Dict:\n",
        "        \"\"\"Simulate a complete draft\"\"\"\n",
        "\n",
        "        # Initialize draft state\n",
        "        state = DraftState(\n",
        "            league=self.league,\n",
        "            available_players=set(self.player_pool.values()),\n",
        "            our_team_id=our_draft_position\n",
        "        )\n",
        "\n",
        "        draft_results = {\n",
        "            'our_picks': [],\n",
        "            'all_picks': [],\n",
        "            'final_roster': [],\n",
        "            'final_value': 0.0,\n",
        "            'round_by_round_value': []\n",
        "        }\n",
        "\n",
        "        pick_number = 1\n",
        "\n",
        "        # Simulate draft round by round\n",
        "        for round_num in range(1, min(rounds_to_simulate + 1, self.league.total_rounds + 1)):\n",
        "            state.current_round = round_num\n",
        "\n",
        "            for pick_in_round in range(1, self.league.teams + 1):\n",
        "                state.current_pick_in_round = pick_in_round\n",
        "                current_team = state.current_team_picking\n",
        "\n",
        "                if not state.available_players:\n",
        "                    break\n",
        "\n",
        "                if current_team == our_draft_position:\n",
        "                    # Our pick\n",
        "                    our_pick = our_strategy.make_pick(state)\n",
        "                    if our_pick:\n",
        "                        state.available_players.discard(our_pick)\n",
        "                        state.team_rosters[current_team].append(our_pick)\n",
        "                        draft_results['our_picks'].append({\n",
        "                            'round': round_num,\n",
        "                            'pick': pick_number,\n",
        "                            'player': our_pick,\n",
        "                            'vorp': our_pick.vorp,\n",
        "                            'position': our_pick.position\n",
        "                        })\n",
        "                        draft_results['all_picks'].append(f\"Pick {pick_number}: {our_pick.name} ({our_pick.position}) - VORP: {our_pick.vorp:.2f}\")\n",
        "                else:\n",
        "                    # Opponent pick\n",
        "                    self.opponent_model.reset_position_runs()  # Reset for each opponent\n",
        "                    opp_pick = self.opponent_model.sample_opponent_pick(state, current_team)\n",
        "                    if opp_pick:\n",
        "                        state.available_players.discard(opp_pick)\n",
        "                        state.team_rosters[current_team].append(opp_pick)\n",
        "                        draft_results['all_picks'].append(f\"Pick {pick_number}: {opp_pick.name} ({opp_pick.position}) [Team {current_team}]\")\n",
        "\n",
        "                pick_number += 1\n",
        "\n",
        "            # Calculate value after each round\n",
        "            our_roster = state.team_rosters[our_draft_position]\n",
        "            round_value = self.reward_function.calculate_roster_value(our_roster, self.league)\n",
        "            draft_results['round_by_round_value'].append(round_value)\n",
        "\n",
        "        # Final results\n",
        "        draft_results['final_roster'] = state.team_rosters[our_draft_position]\n",
        "        draft_results['final_value'] = self.reward_function.calculate_roster_value(\n",
        "            draft_results['final_roster'], self.league\n",
        "        )\n",
        "\n",
        "        return draft_results\n",
        "\n",
        "# Create different strategies\n",
        "strategies = {\n",
        "    'Greedy VORP': GreedyVORPStrategy(),\n",
        "    'ADP Following': ADPStrategy(),\n",
        "    'Positional Needs': PositionalNeedsStrategy(reward_function),\n",
        "    'MCTS': MCTSStrategy(mcts_agent)\n",
        "}\n",
        "\n",
        "# Create simulator\n",
        "simulator = DraftSimulator(player_pool, LEAGUE, opponent_model, reward_function)\n",
        "\n",
        "print(\"‚úÖ Backtesting framework created!\")\n",
        "print(f\"üìä Strategies to test: {list(strategies.keys())}\")\n",
        "print(\"üéØ Ready to run draft simulations!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTcdEZS03Vbp"
      },
      "source": [
        "## 8. Run Backtesting Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKhW_sd_3Vbp"
      },
      "outputs": [],
      "source": [
        "# Run backtesting experiments\n",
        "def run_strategy_comparison(num_simulations: int = 20, draft_positions: List[int] = [1, 6, 12]):\n",
        "    \"\"\"Compare strategies across multiple simulations and draft positions\"\"\"\n",
        "\n",
        "    results = defaultdict(list)\n",
        "    detailed_results = {}\n",
        "\n",
        "    print(f\"üîÑ Running {num_simulations} simulations for each strategy at positions {draft_positions}...\")\n",
        "\n",
        "    for position in draft_positions:\n",
        "        print(f\"\\nüìç Testing draft position {position}:\")\n",
        "\n",
        "        for strategy_name, strategy in strategies.items():\n",
        "            print(f\"   üß™ Testing {strategy_name}...\", end=\" \")\n",
        "\n",
        "            position_results = []\n",
        "            for sim in range(num_simulations):\n",
        "                # Run simulation\n",
        "                result = simulator.simulate_draft(strategy, our_draft_position=position, rounds_to_simulate=8)\n",
        "                position_results.append(result['final_value'])\n",
        "\n",
        "                # Store detailed result for best strategy later\n",
        "                if sim == 0:  # Store first simulation for each strategy\n",
        "                    detailed_results[f\"{strategy_name}_pos{position}\"] = result\n",
        "\n",
        "            # Calculate statistics\n",
        "            avg_value = np.mean(position_results)\n",
        "            std_value = np.std(position_results)\n",
        "            min_value = np.min(position_results)\n",
        "            max_value = np.max(position_results)\n",
        "\n",
        "            results[strategy_name].append({\n",
        "                'position': position,\n",
        "                'avg_value': avg_value,\n",
        "                'std_value': std_value,\n",
        "                'min_value': min_value,\n",
        "                'max_value': max_value,\n",
        "                'all_values': position_results\n",
        "            })\n",
        "\n",
        "            print(f\"Avg: {avg_value:.2f} ¬± {std_value:.2f}\")\n",
        "\n",
        "    return results, detailed_results\n",
        "\n",
        "# Run the comparison (reduced simulations for Colab efficiency)\n",
        "comparison_results, detailed_results = run_strategy_comparison(num_simulations=10, draft_positions=[1, 6, 12])\n",
        "\n",
        "# Create results summary\n",
        "print(f\"\\nüèÜ STRATEGY COMPARISON RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "summary_data = []\n",
        "for strategy_name, position_results in comparison_results.items():\n",
        "    for pos_result in position_results:\n",
        "        summary_data.append({\n",
        "            'Strategy': strategy_name,\n",
        "            'Position': pos_result['position'],\n",
        "            'Avg Value': pos_result['avg_value'],\n",
        "            'Std Dev': pos_result['std_value'],\n",
        "            'Min Value': pos_result['min_value'],\n",
        "            'Max Value': pos_result['max_value']\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Find best strategy overall\n",
        "best_strategy = summary_df.loc[summary_df['Avg Value'].idxmax()]\n",
        "print(f\"\\nü•á BEST PERFORMING STRATEGY:\")\n",
        "print(f\"   Strategy: {best_strategy['Strategy']}\")\n",
        "print(f\"   Position: {best_strategy['Position']}\")\n",
        "print(f\"   Average Value: {best_strategy['Avg Value']:.2f}\")\n",
        "print(f\"   Std Dev: {best_strategy['Std Dev']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1jTYVjx3Vbp"
      },
      "source": [
        "## 9. Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTFu79Q3Vbp"
      },
      "outputs": [],
      "source": [
        "# Visualization of results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Average performance by strategy and position\n",
        "strategy_names = list(comparison_results.keys())\n",
        "positions = [1, 6, 12]\n",
        "x = np.arange(len(positions))\n",
        "width = 0.2\n",
        "\n",
        "for i, strategy in enumerate(strategy_names):\n",
        "    values = [comparison_results[strategy][j]['avg_value'] for j in range(len(positions))]\n",
        "    errors = [comparison_results[strategy][j]['std_value'] for j in range(len(positions))]\n",
        "    axes[0, 0].bar(x + i*width, values, width, label=strategy, alpha=0.8, yerr=errors, capsize=5)\n",
        "\n",
        "axes[0, 0].set_xlabel('Draft Position')\n",
        "axes[0, 0].set_ylabel('Average Roster Value')\n",
        "axes[0, 0].set_title('Strategy Performance by Draft Position')\n",
        "axes[0, 0].set_xticks(x + width * 1.5)\n",
        "axes[0, 0].set_xticklabels(positions)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Box plot of performance distribution\n",
        "all_values = []\n",
        "all_labels = []\n",
        "for strategy in strategy_names:\n",
        "    for pos_idx, position in enumerate(positions):\n",
        "        values = comparison_results[strategy][pos_idx]['all_values']\n",
        "        all_values.append(values)\n",
        "        all_labels.append(f\"{strategy}\\n(Pos {position})\")\n",
        "\n",
        "axes[0, 1].boxplot(all_values, labels=all_labels)\n",
        "axes[0, 1].set_title('Performance Distribution by Strategy')\n",
        "axes[0, 1].set_ylabel('Roster Value')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Strategy performance summary heatmap\n",
        "pivot_data = summary_df.pivot(index='Strategy', columns='Position', values='Avg Value')\n",
        "im = axes[1, 0].imshow(pivot_data.values, cmap='RdYlGn', aspect='auto')\n",
        "axes[1, 0].set_xticks(range(len(pivot_data.columns)))\n",
        "axes[1, 0].set_yticks(range(len(pivot_data.index)))\n",
        "axes[1, 0].set_xticklabels(pivot_data.columns)\n",
        "axes[1, 0].set_yticklabels(pivot_data.index)\n",
        "axes[1, 0].set_title('Strategy Performance Heatmap')\n",
        "axes[1, 0].set_xlabel('Draft Position')\n",
        "\n",
        "# Add values to heatmap\n",
        "for i in range(len(pivot_data.index)):\n",
        "    for j in range(len(pivot_data.columns)):\n",
        "        text = axes[1, 0].text(j, i, f'{pivot_data.iloc[i, j]:.1f}',\n",
        "                              ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "\n",
        "plt.colorbar(im, ax=axes[1, 0], label='Avg Roster Value')\n",
        "\n",
        "# 4. Best strategy details\n",
        "best_key = f\"{best_strategy['Strategy']}_pos{int(best_strategy['Position'])}\"\n",
        "if best_key in detailed_results:\n",
        "    best_detail = detailed_results[best_key]\n",
        "\n",
        "    # Show draft picks for best strategy\n",
        "    pick_data = []\n",
        "    for pick in best_detail['our_picks']:\n",
        "        pick_data.append({\n",
        "            'Round': pick['round'],\n",
        "            'Player': pick['player'].name,\n",
        "            'Position': pick['position'],\n",
        "            'VORP': pick['vorp']\n",
        "        })\n",
        "\n",
        "    pick_df = pd.DataFrame(pick_data)\n",
        "\n",
        "    # Plot draft progression\n",
        "    rounds = pick_df['Round'].values\n",
        "    cumulative_vorp = np.cumsum(pick_df['VORP'].values)\n",
        "\n",
        "    axes[1, 1].plot(rounds, cumulative_vorp, 'o-', linewidth=2, markersize=8)\n",
        "    axes[1, 1].set_xlabel('Round')\n",
        "    axes[1, 1].set_ylabel('Cumulative VORP')\n",
        "    axes[1, 1].set_title(f'Draft Progression - {best_strategy[\"Strategy\"]} (Pos {int(best_strategy[\"Position\"])})')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Annotate key picks\n",
        "    for i, (round_num, vorp) in enumerate(zip(rounds, cumulative_vorp)):\n",
        "        if i < 3:  # Annotate first 3 picks\n",
        "            player_name = pick_df.iloc[i]['Player']\n",
        "            axes[1, 1].annotate(f'{player_name}',\n",
        "                               (round_num, vorp),\n",
        "                               xytext=(5, 5),\n",
        "                               textcoords='offset points',\n",
        "                               fontsize=8, alpha=0.8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed analysis\n",
        "print(f\"\\nüìä DETAILED ANALYSIS OF BEST STRATEGY:\")\n",
        "print(f\"Strategy: {best_strategy['Strategy']} at Position {int(best_strategy['Position'])}\")\n",
        "print(f\"Average Value: {best_strategy['Avg Value']:.2f}\")\n",
        "\n",
        "if best_key in detailed_results:\n",
        "    best_detail = detailed_results[best_key]\n",
        "    print(f\"\\nDraft Picks:\")\n",
        "    for i, pick in enumerate(best_detail['our_picks'], 1):\n",
        "        print(f\"  {i}. Round {pick['round']}: {pick['player'].name} ({pick['position']}) - VORP: {pick['vorp']:.2f}\")\n",
        "\n",
        "    print(f\"\\nFinal Roster Composition:\")\n",
        "    roster_composition = Counter(p.position for p in best_detail['final_roster'])\n",
        "    for pos, count in sorted(roster_composition.items()):\n",
        "        print(f\"  {pos}: {count}\")\n",
        "\n",
        "print(f\"\\nüìà Performance Summary Across All Tests:\")\n",
        "for strategy in strategy_names:\n",
        "    avg_performance = np.mean([result['avg_value'] for result in comparison_results[strategy]])\n",
        "    std_performance = np.mean([result['std_value'] for result in comparison_results[strategy]])\n",
        "    print(f\"  {strategy:20s}: {avg_performance:6.2f} ¬± {std_performance:.2f} average\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSBr4Srs3Vbq"
      },
      "outputs": [],
      "source": [
        "# Add GPU-accelerated MCTS strategy if available\n",
        "if GPU_AVAILABLE:\n",
        "    gpu_mcts_strategy = AdaptiveMCTSStrategy(\n",
        "        opponent_model=opponent_model,\n",
        "        reward_function=reward_function,\n",
        "        value_function=value_function,\n",
        "        simulations_per_move=1200,  # More simulations on GPU\n",
        "        c_param=1.4,\n",
        "        use_gpu=True\n",
        "    )\n",
        "\n",
        "    # Add to strategies dict (assuming it exists)\n",
        "    if 'strategies' in globals():\n",
        "        strategies['MCTS (GPU)'] = gpu_mcts_strategy\n",
        "        print(\"üöÄ GPU-accelerated MCTS strategy added!\")\n",
        "        print(\"üìä GPU simulations: 1200 (vs CPU: 400)\")\n",
        "        print(f\"‚ö° Expected speedup: 3-5x on T4 GPU\")\n",
        "    else:\n",
        "        print(\"üíæ GPU strategy ready - will be added when strategies dict is created\")\n",
        "else:\n",
        "    print(\"üìä GPU not available - using CPU strategies only\")\n",
        "\n",
        "# GPU Memory optimization for long backtests\n",
        "if GPU_AVAILABLE:\n",
        "    def gpu_memory_cleanup():\n",
        "        \"\"\"Clean up GPU memory between simulations\"\"\"\n",
        "        torch.cuda.empty_cache()\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"üßπ GPU memory freed: {torch.cuda.memory_reserved(0)/1e9:.1f}GB reserved\")\n",
        "\n",
        "    # Schedule cleanup every 10 simulations during backtesting\n",
        "    print(\"üîß GPU memory management enabled\")\n",
        "else:\n",
        "    def gpu_memory_cleanup():\n",
        "        pass  # No-op for CPU\n",
        "\n",
        "print(\"‚úÖ GPU optimization setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCef2dQZ3Vbq"
      },
      "source": [
        "## 10. Save Best Model and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcFWhAoH3Vbq"
      },
      "outputs": [],
      "source": [
        "# Save the best performing model and all results\n",
        "print(\"üíæ Saving best model and results...\")\n",
        "\n",
        "# Identify the best strategy\n",
        "best_strategy_name = best_strategy['Strategy']\n",
        "best_strategy_obj = strategies[best_strategy_name]\n",
        "\n",
        "# Prepare model package for saving\n",
        "model_package = {\n",
        "    'best_strategy_name': best_strategy_name,\n",
        "    'best_strategy_object': best_strategy_obj,\n",
        "    'best_performance': {\n",
        "        'strategy': best_strategy['Strategy'],\n",
        "        'position': int(best_strategy['Position']),\n",
        "        'avg_value': best_strategy['Avg Value'],\n",
        "        'std_dev': best_strategy['Std Dev']\n",
        "    },\n",
        "    'player_pool': player_pool,\n",
        "    'league_settings': LEAGUE,\n",
        "    'opponent_model': opponent_model,\n",
        "    'reward_function': reward_function,\n",
        "    'value_function': value_function,\n",
        "    'mcts_agent': mcts_agent if best_strategy_name == 'MCTS' else None,\n",
        "    'comparison_results': comparison_results,\n",
        "    'detailed_results': detailed_results,\n",
        "    'summary_dataframe': summary_df,\n",
        "    'hyperparameters': {\n",
        "        'mcts_simulations': 200,\n",
        "        'risk_penalty': reward_function.risk_penalty,\n",
        "        'overstack_penalty': reward_function.overstack_penalty,\n",
        "        'bye_penalty': reward_function.bye_penalty,\n",
        "        'opponent_temperature': opponent_model.temperature,\n",
        "        'position_run_prob': opponent_model.position_run_prob\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to pickle file\n",
        "import pickle\n",
        "\n",
        "with open('best_draft_strategy_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_package, f)\n",
        "\n",
        "print(f\"‚úÖ Best model saved: {best_strategy_name}\")\n",
        "print(f\"üìÅ File: best_draft_strategy_model.pkl\")\n",
        "\n",
        "# Create a summary report\n",
        "report = f\\\"\\\"\\\"\n",
        "üèà FANTASY FOOTBALL DRAFT STRATEGY ANALYSIS REPORT\n",
        "{'='*60}\n",
        "\n",
        "EXPERIMENT OVERVIEW:\n",
        "‚Ä¢ Strategies Tested: {len(strategies)}\n",
        "‚Ä¢ Draft Positions: [1, 6, 12]\n",
        "‚Ä¢ Simulations per Strategy: 10\n",
        "‚Ä¢ Rounds Simulated: 8\n",
        "\n",
        "BEST PERFORMING STRATEGY:\n",
        "‚Ä¢ Strategy: {best_strategy['Strategy']}\n",
        "‚Ä¢ Draft Position: {int(best_strategy['Position'])}\n",
        "‚Ä¢ Average Roster Value: {best_strategy['Avg Value']:.2f}\n",
        "‚Ä¢ Standard Deviation: {best_strategy['Std Dev']:.2f}\n",
        "\n",
        "STRATEGY RANKINGS (by average performance):\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "# Calculate overall rankings\n",
        "strategy_rankings = []\n",
        "for strategy in strategy_names:\n",
        "    avg_performance = np.mean([result['avg_value'] for result in comparison_results[strategy]])\n",
        "    strategy_rankings.append((strategy, avg_performance))\n",
        "\n",
        "strategy_rankings.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for i, (strategy, avg_perf) in enumerate(strategy_rankings, 1):\n",
        "    report += f\"{i}. {strategy:<20s}: {avg_perf:6.2f}\\\\n\"\n",
        "\n",
        "# Add detailed picks for best strategy\n",
        "if best_key in detailed_results:\n",
        "    best_detail = detailed_results[best_key]\n",
        "    report += f\\\"\\\\nBEST STRATEGY DRAFT EXAMPLE:\\\\n\\\"\n",
        "    for i, pick in enumerate(best_detail['our_picks'], 1):\n",
        "        report += f\"Round {pick['round']:2d}: {pick['player'].name:<25s} ({pick['position']}) - VORP: {pick['vorp']:5.2f}\\\\n\"\n",
        "\n",
        "report += f\\\"\\\\nMODEL COMPONENTS:\\\\n\\\"\n",
        "report += f\"‚Ä¢ Player Pool: {len(player_pool)} players\\\\n\\\"\n",
        "report += f\"‚Ä¢ MCTS Simulations: {mcts_agent.simulations}\\\\n\\\"\n",
        "report += f\"‚Ä¢ Risk Penalty (Œª): {reward_function.risk_penalty}\\\\n\\\"\n",
        "report += f\"‚Ä¢ Opponent Temperature: {opponent_model.temperature}\\\\n\\\"\n",
        "\n",
        "report += f\\\"\\\\nFILES GENERATED:\\\\n\\\"\n",
        "report += f\"‚Ä¢ best_draft_strategy_model.pkl - Complete model package\\\\n\\\"\n",
        "report += f\"‚Ä¢ draft_strategy_report.txt - This analysis report\\\\n\\\"\n",
        "\n",
        "# Save report\n",
        "with open('draft_strategy_report.txt', 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(report)\n",
        "\n",
        "# Create a simple usage example\n",
        "usage_example = f\\\"\\\"\\\"\n",
        "# Example: How to use the saved draft strategy model\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "# Load the best model\n",
        "with open('best_draft_strategy_model.pkl', 'rb') as f:\n",
        "    model_package = pickle.load(f)\n",
        "\n",
        "best_strategy = model_package['best_strategy_object']\n",
        "player_pool = model_package['player_pool']\n",
        "league_settings = model_package['league_settings']\n",
        "\n",
        "# Example: Get recommendation for current draft state\n",
        "# (You would update this with real draft state)\n",
        "from models.draft_strategy_mcts import DraftState\n",
        "\n",
        "current_state = DraftState(\n",
        "    league=league_settings,\n",
        "    available_players=set(player_pool.values()),\n",
        "    our_team_id=1  # Your team ID\n",
        ")\n",
        "\n",
        "# Get the best pick recommendation\n",
        "recommended_pick = best_strategy.make_pick(current_state)\n",
        "print(f\"Recommended pick: {{recommended_pick.name}} ({{recommended_pick.position}}) - VORP: {{recommended_pick.vorp:.2f}}\")\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "with open('model_usage_example.py', 'w') as f:\n",
        "    f.write(usage_example)\n",
        "\n",
        "print(f\"\\\\nüìã Additional files created:\")\n",
        "print(f\"   ‚Ä¢ draft_strategy_report.txt - Full analysis report\")\n",
        "print(f\"   ‚Ä¢ model_usage_example.py - Usage example\")\n",
        "\n",
        "print(f\"\\\\nüéØ SUMMARY:\")\n",
        "print(f\"Best Strategy: {best_strategy_name}\")\n",
        "print(f\"Performance: {best_strategy['Avg Value']:.2f} roster value\")\n",
        "print(f\"Improvement over worst: {best_strategy['Avg Value'] - strategy_rankings[-1][1]:.2f}\")\n",
        "print(f\"\\\\n‚úÖ Model training and backtesting complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh6WeRVY3Vbq"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook implemented and compared multiple draft strategies for fantasy football:\n",
        "\n",
        "### üèÜ **Strategies Tested:**\n",
        "1. **MCTS** - Monte Carlo Tree Search with long-horizon planning\n",
        "2. **Positional Needs** - VORP-based with positional bonuses\n",
        "3. **Greedy VORP** - Simple highest-value available\n",
        "4. **ADP Following** - Follows consensus rankings\n",
        "\n",
        "### üîç **Key Findings:**\n",
        "- **Best Strategy**: The analysis will identify which approach performs best across different draft positions\n",
        "- **MCTS Performance**: Shows how well the sophisticated planning approach compares to simpler heuristics\n",
        "- **Position Effects**: Different strategies may work better at different draft positions\n",
        "- **Risk vs Reward**: The risk penalty parameter (Œª) affects rookie valuation and strategy performance\n",
        "\n",
        "### üíæ **Files Generated:**\n",
        "- `best_draft_strategy_model.pkl` - Complete trained model package\n",
        "- `draft_strategy_report.txt` - Detailed analysis report\n",
        "- `model_usage_example.py` - Code example for using the model\n",
        "\n",
        "### üöÄ **Next Steps:**\n",
        "1. **Deploy the best model** for live draft assistance\n",
        "2. **Fine-tune hyperparameters** (risk penalty, MCTS simulations)\n",
        "3. **Add more sophisticated features** (college stats, combine metrics)\n",
        "4. **Implement position-specific models** for better accuracy\n",
        "5. **Create real-time draft tracker** integration\n",
        "\n",
        "**The winning strategy can now be used for actual fantasy football drafts!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgR9ZEHx3Vbq"
      },
      "source": [
        "### üöÄ GPU Performance Monitoring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4QFx4j63Vbq"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class PerformanceMonitor:\n",
        "    \"\"\"Monitor GPU/CPU performance during MCTS backtesting\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stats = {\n",
        "            'total_simulations': 0,\n",
        "            'gpu_simulations': 0,\n",
        "            'cpu_simulations': 0,\n",
        "            'total_time': 0,\n",
        "            'gpu_time': 0,\n",
        "            'cpu_time': 0,\n",
        "            'memory_usage': []\n",
        "        }\n",
        "        self.start_time = None\n",
        "\n",
        "    def start_simulation(self, strategy_name: str):\n",
        "        \"\"\"Start timing a simulation\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        self.current_strategy = strategy_name\n",
        "\n",
        "        if GPU_AVAILABLE and torch.cuda.is_available():\n",
        "            # Record GPU memory before simulation\n",
        "            memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
        "            self.stats['memory_usage'].append({\n",
        "                'timestamp': datetime.now(),\n",
        "                'strategy': strategy_name,\n",
        "                'memory_gb': memory_used\n",
        "            })\n",
        "\n",
        "    def end_simulation(self):\n",
        "        \"\"\"End timing and record stats\"\"\"\n",
        "        if self.start_time is None:\n",
        "            return\n",
        "\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.stats['total_time'] += elapsed\n",
        "        self.stats['total_simulations'] += 1\n",
        "\n",
        "        if 'GPU' in self.current_strategy:\n",
        "            self.stats['gpu_time'] += elapsed\n",
        "            self.stats['gpu_simulations'] += 1\n",
        "        else:\n",
        "            self.stats['cpu_time'] += elapsed\n",
        "            self.stats['cpu_simulations'] += 1\n",
        "\n",
        "        self.start_time = None\n",
        "\n",
        "    def get_performance_summary(self):\n",
        "        \"\"\"Get performance summary\"\"\"\n",
        "        if self.stats['total_simulations'] == 0:\n",
        "            return \"No simulations completed yet\"\n",
        "\n",
        "        summary = f\"\"\"\n",
        "üèÅ Performance Summary:\n",
        "{'='*50}\n",
        "üìä Total Simulations: {self.stats['total_simulations']}\n",
        "‚è±Ô∏è  Total Time: {self.stats['total_time']:.1f}s\n",
        "üìà Avg Time/Sim: {self.stats['total_time']/self.stats['total_simulations']:.2f}s\n",
        "\n",
        "\"\"\"\n",
        "        if self.stats['gpu_simulations'] > 0:\n",
        "            gpu_avg = self.stats['gpu_time'] / self.stats['gpu_simulations']\n",
        "            summary += f\"\"\"üöÄ GPU Performance:\n",
        "   - Simulations: {self.stats['gpu_simulations']}\n",
        "   - Total Time: {self.stats['gpu_time']:.1f}s\n",
        "   - Avg Time: {gpu_avg:.2f}s/sim\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        if self.stats['cpu_simulations'] > 0:\n",
        "            cpu_avg = self.stats['cpu_time'] / self.stats['cpu_simulations']\n",
        "            summary += f\"\"\"üìä CPU Performance:\n",
        "   - Simulations: {self.stats['cpu_simulations']}\n",
        "   - Total Time: {self.stats['cpu_time']:.1f}s\n",
        "   - Avg Time: {cpu_avg:.2f}s/sim\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        if self.stats['gpu_simulations'] > 0 and self.stats['cpu_simulations'] > 0:\n",
        "            cpu_avg = self.stats['cpu_time'] / self.stats['cpu_simulations']\n",
        "            gpu_avg = self.stats['gpu_time'] / self.stats['gpu_simulations']\n",
        "            speedup = cpu_avg / gpu_avg if gpu_avg > 0 else 0\n",
        "            summary += f\"\"\"‚ö° GPU Speedup: {speedup:.1f}x faster than CPU\n",
        "\"\"\"\n",
        "\n",
        "        if GPU_AVAILABLE and self.stats['memory_usage']:\n",
        "            max_memory = max(m['memory_gb'] for m in self.stats['memory_usage'])\n",
        "            summary += f\"\"\"üíæ Peak GPU Memory: {max_memory:.1f} GB\n",
        "\"\"\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "# Create global performance monitor\n",
        "perf_monitor = PerformanceMonitor()\n",
        "\n",
        "# Enhanced backtesting function with performance monitoring\n",
        "def run_gpu_optimized_backtest(strategies, positions=[1, 6, 12], num_simulations=3):\n",
        "    \"\"\"\n",
        "    Run backtest with GPU performance monitoring and memory management\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Starting GPU-optimized backtest...\")\n",
        "\n",
        "    results = {}\n",
        "    detailed_results = {}\n",
        "\n",
        "    for strategy_name, strategy in strategies.items():\n",
        "        print(f\"\\nüß™ Testing {strategy_name}...\")\n",
        "        results[strategy_name] = []\n",
        "\n",
        "        for position in positions:\n",
        "            print(f\"   üìç Position {position}...\", end=\" \")\n",
        "\n",
        "            position_results = []\n",
        "            for sim in range(num_simulations):\n",
        "                # Performance monitoring\n",
        "                perf_monitor.start_simulation(strategy_name)\n",
        "\n",
        "                # Run simulation\n",
        "                result = simulator.simulate_draft(strategy, our_draft_position=position, rounds_to_simulate=8)\n",
        "                position_results.append(result['final_value'])\n",
        "\n",
        "                # End performance monitoring\n",
        "                perf_monitor.end_simulation()\n",
        "\n",
        "                # GPU memory cleanup every 5 simulations\n",
        "                if sim % 5 == 0:\n",
        "                    gpu_memory_cleanup()\n",
        "\n",
        "                # Store detailed result for analysis\n",
        "                if sim == 0:\n",
        "                    detailed_results[f\"{strategy_name}_pos{position}\"] = result\n",
        "\n",
        "            # Calculate statistics\n",
        "            avg_value = np.mean(position_results)\n",
        "            std_value = np.std(position_results)\n",
        "\n",
        "            results[strategy_name].append({\n",
        "                'position': position,\n",
        "                'avg_value': avg_value,\n",
        "                'std_value': std_value,\n",
        "                'all_values': position_results\n",
        "            })\n",
        "\n",
        "            print(f\"Avg: {avg_value:.2f} ¬± {std_value:.2f}\")\n",
        "\n",
        "    # Print performance summary\n",
        "    print(perf_monitor.get_performance_summary())\n",
        "\n",
        "    return results, detailed_results\n",
        "\n",
        "print(\"‚úÖ GPU-optimized backtesting ready!\")\n",
        "print(\"üí° Use run_gpu_optimized_backtest() instead of regular backtest for performance monitoring\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvyvytyx3Vbr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmConHm73Vbr"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}